{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7CCJZKdcC2"
      },
      "source": [
        "# Building a Chatbot from Scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsR2PuNPdcC5"
      },
      "source": [
        "##### In this project we will build a chatbot from scratch using the corenell University's Movie Dialogue corpus.\n",
        "##### We will be using a deep learning based architecture with the main components as a lstm based encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ADrJf54A9oP",
        "outputId": "fb44d499-0172-43e0-f46b-5175b62489d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr5XzL_HCGH2",
        "outputId": "029cce17-14ad-4398-ad6d-dd060d7e7e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.1.2\n",
            "  Downloading Keras-2.1.2-py2.py3-none-any.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.3/304.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras==2.1.2) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras==2.1.2) (1.11.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras==2.1.2) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras==2.1.2) (6.0.1)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.14.0 requires keras<2.15,>=2.14.0, but you have keras 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install keras==2.1.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVZIfjg8MvRH",
        "outputId": "d8606e79-b7ad-406e-aea7-1d705e005e5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nltk==3.4.1\n",
            "  Downloading nltk-3.4.1.zip (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk==3.4.1) (1.16.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.1-py3-none-any.whl size=1445938 sha256=2617b1a2558ad298b473f6f47ff2429e4cda16840c4c87e9946d29775ce22797\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d3/44/40093a2c426178152412db9ad7dbf514ba3f13725b3e53f60f\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed nltk-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install  nltk==3.4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pdck_GPq908",
        "outputId": "f0c67fc9-f1c4-4e75-d7a1-40ff91f9400a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git\n",
            "  Cloning https://github.com/MeMartijn/updated-sklearn-crfsuite.git to /tmp/pip-req-build-5ckcdh8h\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MeMartijn/updated-sklearn-crfsuite.git /tmp/pip-req-build-5ckcdh8h\n",
            "  Resolved https://github.com/MeMartijn/updated-sklearn-crfsuite.git to commit 675038761b4405f04691a83339d04903790e2b95\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6) (4.66.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6) (1.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn-crfsuite==0.3.6) (0.9.0)\n",
            "Collecting python-crfsuite>=0.8.3 (from sklearn-crfsuite==0.3.6)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: sklearn-crfsuite\n",
            "  Building wheel for sklearn-crfsuite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn-crfsuite: filename=sklearn_crfsuite-0.3.6-py2.py3-none-any.whl size=10866 sha256=1c52e977fd65172dfa84361190bc46d12358f0f8626e60239c7e95ece5998e97\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-isye_gzx/wheels/0b/bc/07/bd75a6f5fa2bf2ea05a5aad8d9ac66d2b5aab93dfd4e1a89de\n",
            "Successfully built sklearn-crfsuite\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.9 sklearn-crfsuite-0.3.6\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git #egg=sklearn_crfsuite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AmU6YSE9ifAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47a2ae9-98bd-443c-d49b-8bca2d381719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Keras\n",
            "Version: 2.1.2\n",
            "Summary: Deep Learning for Python\n",
            "Home-page: https://github.com/fchollet/keras\n",
            "Author: Francois Chollet\n",
            "Author-email: francois.chollet@gmail.com\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: numpy, pyyaml, scipy, six\n",
            "Required-by: tensorflow\n"
          ]
        }
      ],
      "source": [
        "!pip3 show keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvRe_rDeoSO4",
        "outputId": "7f8708ad-f5a3-424f-cee7-62219ff093db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: nltk\n",
            "Version: 3.4.1\n",
            "Summary: Natural Language Toolkit\n",
            "Home-page: http://nltk.org/\n",
            "Author: Steven Bird\n",
            "Author-email: stevenbird1@gmail.com\n",
            "License: Apache License, Version 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: six\n",
            "Required-by: textblob\n"
          ]
        }
      ],
      "source": [
        "!pip show nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WlpUO5tDkH"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT7RUDWgMvOC",
        "outputId": "50852638-6b26-4c64-a425-727041c476aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.2.2\n"
          ]
        }
      ],
      "source": [
        "print(sklearn.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsQlOMEcUByn",
        "outputId": "07d9dc68-2a71-41a6-8b80-c1660b16f4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: numpy\n",
            "Version: 1.23.5\n",
            "Summary: NumPy is the fundamental package for array computing with Python.\n",
            "Home-page: https://www.numpy.org\n",
            "Author: Travis E. Oliphant et al.\n",
            "Author-email: \n",
            "License: BSD\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: albumentations, altair, arviz, astropy, autograd, blis, bokeh, bqplot, chex, cmdstanpy, contourpy, cufflinks, cupy-cuda11x, cvxpy, datascience, db-dtypes, dopamine-rl, ecos, flax, folium, geemap, gensim, gym, h5py, holoviews, hyperopt, ibis-framework, imageio, imbalanced-learn, imgaug, jax, jaxlib, Keras, librosa, lida, lightgbm, matplotlib, matplotlib-venn, missingno, mizani, ml-dtypes, mlxtend, moviepy, music21, nibabel, numba, numexpr, opencv-contrib-python, opencv-python, opencv-python-headless, opt-einsum, optax, orbax-checkpoint, osqp, pandas, pandas-gbq, patsy, plotnine, prophet, pyarrow, pycocotools, pyerfa, pymc, pytensor, python-louvain, PyWavelets, qdldl, qudida, scikit-image, scikit-learn, scipy, scs, seaborn, shapely, sklearn-pandas, soxr, spacy, stanio, statsmodels, tables, tensorboard, tensorflow, tensorflow-datasets, tensorflow-hub, tensorflow-probability, tensorstore, thinc, tifffile, torchtext, torchvision, wordcloud, xarray, xarray-einstats, xgboost, yellowbrick, yfinance\n"
          ]
        }
      ],
      "source": [
        "!pip show numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVpvajlKZU06"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYR3BX4YedBA"
      },
      "source": [
        "Did some libraby level changes in 3.10 version to import keras\n",
        "\n",
        "Error faced is :-\n",
        "\n",
        "ImportError: cannot import name 'Iterable' from 'collections' ( /usr/local/lib/python3.10/dist-packages/keras/callbacks.py )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gY5YL8TL98Ei"
      },
      "outputs": [],
      "source": [
        "from collections.abc import Iterable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UE69aFYBcSKV"
      },
      "outputs": [],
      "source": [
        "!cp /usr/local/lib/python3.10/dist-packages/keras/callbacks.py /usr/local/lib/python3.10/dist-packages/keras/callbacks_bak.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfphHdWBcSHh",
        "outputId": "b6130e53-a009-47a4-90a5-411653ea2159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from collections import deque\n",
            "from collections import OrderedDict\n",
            "from collections import Iterable\n"
          ]
        }
      ],
      "source": [
        "!cat /usr/local/lib/python3.10/dist-packages/keras/callbacks.py | grep -i 'collections'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SyYMGCLYbDoG"
      },
      "outputs": [],
      "source": [
        "!sudo sed -i -e 's/from collections import Iterable/from collections.abc import Iterable/' /usr/local/lib/python3.10/dist-packages/keras/callbacks.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOzA0Bu7eXC-",
        "outputId": "66939f15-2d61-4f59-c81e-ec05b14bea13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from collections import deque\n",
            "from collections import OrderedDict\n",
            "from collections.abc import Iterable\n"
          ]
        }
      ],
      "source": [
        "!cat /usr/local/lib/python3.10/dist-packages/keras/callbacks.py | grep -i 'collections'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "x30wyuKJ5z8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0617acaf-753a-49fc-9b41-9ffc276203ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V7b5o0oxdcC7"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model\n",
        "#from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_WFN5fXsdcDB"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import nltk\n",
        "import numpy\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "289UF4j6JYm-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IQF3dSidcDI"
      },
      "source": [
        "Please make sure that the version of the respective packages are met to the requirement. sklearn and numpy can't be downgraded in collab so using the standard ones and applying any hacks as required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "oCL0434GdcDK"
      },
      "outputs": [],
      "source": [
        "assert keras.__version__=='2.1.2'\n",
        "assert nltk.__version__=='3.4.1'\n",
        "#assert sklearn.__version__=='0.21.2'\n",
        "#assert numpy.__version__=='1.12.1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv38ReVtdcDO"
      },
      "source": [
        "Download the glove model available at https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Specification : Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXuwJNpGdcDQ"
      },
      "source": [
        "you can download it with 'wget' or can directly put the embedding zip file inside 'embedding_data' folder and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHx1FnytdcDU",
        "outputId": "53fc7d28-c5f8-4f60-9582-15fe5cba7ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1449M  100 1449M    0     0  5167k      0  0:04:47  0:04:47 --:--:-- 5090k\n"
          ]
        }
      ],
      "source": [
        "! curl -O http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhruggPu7iSm",
        "outputId": "1297a13c-b220-41bb-981f-9806d7137254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR9BfMmq7rfY",
        "outputId": "1abfd66a-8d95-46b0-aa90-07dc9bf9c21c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean_text_stop_word_removed.txt              moviequotes.memorable_quotes.txt\n",
            "INDUS_TOKEN_KERA_latest_16_2_30_PM.ipynb      moviequotes.scripts.txt\n",
            "movie_lines_cleaned.txt                       README.v1.0.txt\n",
            "moviequotes.memorable_nonmemorable_pairs.txt\n"
          ]
        }
      ],
      "source": [
        "ls /content/drive/MyDrive/INDUSTRY/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8GdBgXHAMZA",
        "outputId": "2b1fa3f5-071b-4fe5-de12-a0529f90e71e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean_text_whitelisted_removal_18.txt     glove.twitter.27B.zip\n",
            "clean_text_whitelisted_removal_18_v3.txt  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKZbuY9JAOr-",
        "outputId": "b84d4c82-1e36-4986-a5d4-4d0345b000c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: glove.twitter.27B.25d.txt  \n",
            "  inflating: glove.twitter.27B.50d.txt  \n",
            "  inflating: glove.twitter.27B.100d.txt  \n",
            "  inflating: glove.twitter.27B.200d.txt  \n"
          ]
        }
      ],
      "source": [
        "!unzip glove*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "rkAzRRYrQYEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_yG4mV2dcDZ"
      },
      "outputs": [],
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = 'cornell'\n",
        "DATA_PATH = 'clean_text_whitelisted_removal_18_v3.txt'\n",
        "GLOVE_MODEL = \"glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH =  DATA_SET_NAME + '/word-glove-weights.h5'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKA3WnoNdcDk"
      },
      "source": [
        "Load the glove word embedding in to a dictionary where the **key** is a unique **word token** and the **value** is a **d** dimension vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ6Q6VpHdcDn"
      },
      "source": [
        "# Test-1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the Glove Vector Model and loading the dictionary which would be used in subsequent code to get the word embeddings."
      ],
      "metadata": {
        "id": "ckfiFkgroXhC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_DtZYF8_dcDp"
      },
      "outputs": [],
      "source": [
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        '''write here. write your code to load the data in to the dictionary\n",
        "        make sure the value is a numpy array of size 100\n",
        "        max  3 to 6 lines of code'''\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        _word2embedding[word] = vector\n",
        "    file.close()\n",
        "    return _word2embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdoRZsWEdcDs"
      },
      "outputs": [],
      "source": [
        "word2embedding = load_glove_vector()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify the model and if its doing desired mappning."
      ],
      "metadata": {
        "id": "JZdMRBXfpY_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(word2embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc4ZaaToSJ8V",
        "outputId": "06c64940-bcbd-4d64-86cf-a04872e62e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2embedding['do']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CILX6-7yShD6",
        "outputId": "203818d1-c154-4a91-e2b8-b448a1ffed53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.3741e-01, -2.2434e-01,  9.1622e-01, -5.8550e-02, -1.6511e-01,\n",
              "        2.5111e-01,  6.0232e-01, -5.0023e-01,  5.4699e-01,  6.9742e-01,\n",
              "       -2.0822e-01, -1.1138e+00, -5.3540e+00,  4.4314e-01, -5.4168e-01,\n",
              "       -1.7297e-01, -8.2312e-01, -2.0724e-01,  5.2782e-01, -2.1240e-01,\n",
              "        2.9266e-02, -7.1848e-02, -1.3079e-01, -7.4409e-02,  3.6398e-01,\n",
              "       -1.7687e+00,  5.0954e-01,  7.1843e-01,  1.6063e-01, -1.3972e-01,\n",
              "        9.4257e-01, -4.2210e-01,  4.7313e-02, -4.6057e-01, -1.0714e+00,\n",
              "       -2.8972e-03,  1.9650e-01, -5.9106e-01, -1.1389e+00,  1.5337e-01,\n",
              "       -2.1414e+00,  7.8533e-01,  1.0681e-01, -1.0814e-01, -6.3045e-01,\n",
              "        2.1288e-01, -9.9607e-02, -4.1917e-01, -5.7476e-01, -1.1047e+00,\n",
              "        5.3964e-01,  4.9028e-01,  2.6830e-01,  2.7167e-01,  1.6113e-01,\n",
              "        4.2814e-01, -9.7108e-01,  7.5670e-01, -2.8024e-02,  5.9043e-01,\n",
              "       -2.5249e-01, -1.4199e-01,  3.4776e-01,  8.7260e-02,  1.6208e-01,\n",
              "       -1.3040e-01,  2.7808e-02, -2.5873e-01, -1.1011e-02,  1.3697e-01,\n",
              "        2.6576e-01, -7.3448e-01, -1.3408e-01, -1.7406e-01, -6.3658e-02,\n",
              "       -5.4090e-01,  3.1872e-01, -3.6860e-01,  4.6780e-03,  4.5205e-01,\n",
              "        4.4172e-01,  3.5350e-01, -8.2819e-01,  3.2221e-01,  7.2283e-01,\n",
              "        7.4891e-01,  3.5870e-01, -2.9725e-01,  3.9902e-02, -1.4895e-01,\n",
              "       -1.0915e+00,  5.3089e-01,  3.6266e-02, -7.1258e-01, -5.5899e-01,\n",
              "        1.0474e-01,  1.8477e-01,  4.7999e-01,  2.7531e-01,  5.0398e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(word2embedding['everything'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfSKDvEGSohF",
        "outputId": "0b891f0f-425b-426a-9883-dc4539510416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FplY7anCSods"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1WwP20dcDw"
      },
      "source": [
        "# Check-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VknKfgmGdcDz",
        "outputId": "19d57cd6-c519-4fe2-eb99-04efa09656e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.32053 99\n"
          ]
        }
      ],
      "source": [
        "assert len(word2embedding.keys())==1193514\n",
        "for key in word2embedding.keys():\n",
        "    try:\n",
        "        assert len(word2embedding[key])==100\n",
        "    except AssertionError:\n",
        "        print (key,len(word2embedding[key]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCix18rAdcD7"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkKBqppEdcD8"
      },
      "outputs": [],
      "source": [
        "target_counter = Counter()\n",
        "lines = open('clean_text_whitelisted_removal_18_v3.txt', 'rt', encoding='utf8').read().split('\\n')\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "prev_words = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "CHS4Q0nqKwIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    '''Clean text by removing unnecessary characters and altering the format of words.'''\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = re.sub(r'\\*', \"\", text)\n",
        "    text = re.sub(r'\\&', \"\", text)\n",
        "    text = re.sub(r'\\%', \"\", text)\n",
        "    text = re.sub(r'\\^', \"\", text)\n",
        "    text = re.sub(r'\\_', \"\", text)\n",
        "    text = re.sub(r'\\$', \" \", text)\n",
        "    text = re.sub(r'\\[', \" \", text)\n",
        "    text = re.sub(r'\\]', \" \", text)\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "Aj2g26tMHgq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKedj2KK7TcC",
        "outputId": "82da5670-968b-404b-bb07-00f15ebb4689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH1 = '/content/clean_text_whitelisted_removal_18_v3.txt'"
      ],
      "metadata": {
        "id": "vCNb91ocUK8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines3 = open(DATA_PATH1, 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "0-gywhZm7o8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "yy3WUiZJUSjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_list=[]\n",
        "\n",
        "for line in lines3:\n",
        "  word_text = line.split()\n",
        "  temp = []\n",
        "  for item in word_text:\n",
        "    #print(item)\n",
        "    item1 = clean_text(item)\n",
        "    temp.append(item1)\n",
        "  #print(temp)\n",
        "  clean_list.append(temp)\n"
      ],
      "metadata": {
        "id": "I93msXy19bzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_list[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3JBg6Is9bvo",
        "outputId": "0ae48a25-67f1-421d-d0b8-76d8dcaf9d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['they', 'do', 'not'],\n",
              " ['they', 'do', 'to'],\n",
              " ['i', 'hope', 'so'],\n",
              " ['she', 'okay'],\n",
              " [\"let's\", 'go'],\n",
              " ['wow'],\n",
              " ['okay', 'you', 'are', 'gonna', 'need', 'to', 'learn', 'how', 'to', 'lie'],\n",
              " ['no'],\n",
              " ['i',\n",
              "  'am',\n",
              "  'kidding',\n",
              "  'you',\n",
              "  'know',\n",
              "  'how',\n",
              "  'sometimes',\n",
              "  'you',\n",
              "  'just',\n",
              "  'become',\n",
              "  'this',\n",
              "  'persona',\n",
              "  'and',\n",
              "  'you',\n",
              "  'do',\n",
              "  'not',\n",
              "  'know',\n",
              "  'how',\n",
              "  'to',\n",
              "  'quit'],\n",
              " ['like', 'my', 'fear', 'of', 'wearing', 'pastels']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('clean_text_whitelisted1.txt', 'w') as f:\n",
        "      for line in clean_list:\n",
        "          listToStr = ' '.join([str(elem) for i,elem in enumerate(line)])\n",
        "          f.write(f\"{listToStr}\\n\")"
      ],
      "metadata": {
        "id": "mYvSIyGO9bsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFKXFjV69bqM",
        "outputId": "2f12828d-a560-4013-e059-ac6d2b802034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5251264\n",
            "-rw-r--r-- 1 root root    9006648 Nov 18 02:55 clean_text_whitelisted_removal_18_v3.txt\n",
            "-rw-rw-r-- 1 root root 1021669379 Aug 14  2014 glove.twitter.27B.100d.txt\n",
            "-rw-rw-r-- 1 root root 2057590469 Aug 14  2014 glove.twitter.27B.200d.txt\n",
            "-r--r--r-- 1 root root  257699726 Aug 14  2014 glove.twitter.27B.25d.txt\n",
            "-rw-rw-r-- 1 root root  510887943 Aug 14  2014 glove.twitter.27B.50d.txt\n",
            "-rw-r--r-- 1 root root 1520408563 Nov 18 03:02 glove.twitter.27B.zip\n",
            "drwxr-xr-x 1 root root       4096 Nov 16 14:27 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp clean_text_whitelisted1.txt /content/drive/MyDrive/INDUSTRY/"
      ],
      "metadata": {
        "id": "rjzJ9BhB-wga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9mg3YMzD-wc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH1 = 'clean_text_whitelisted_removal_18_v3.txt'\n",
        "\n",
        "lines3 = open(DATA_PATH1, 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "J5PggTtN-wa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_text = []\n",
        "\n",
        "for sent in lines3:\n",
        "    word_text.append(word_tokenize(sent))\n",
        "\n",
        "#print(word_text)\n",
        "#print('**********************************************')\n",
        "print(len(word_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODZ_8anz7o5t",
        "outputId": "b817bf0d-23dd-4ae5-b0e2-1830b993ae1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "287870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_text[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSsAehRz81Ra",
        "outputId": "83372ec8-ebd3-4e31-9ddc-7cf99b3db0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords_en = set(stopwords.words(\"english\"))\n",
        "print(stopwords_en)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-yGQeXE81PT",
        "outputId": "fb0c64bf-8341-43be-bba7-9835eae9542c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"won't\", 'at', 'her', 'before', 'out', 'what', 'who', 'didn', 'his', 't', 'm', \"it's\", \"wouldn't\", 'for', 'being', 'how', 'were', 'so', 'has', 'our', 'himself', 'down', 'yourself', 'those', 'did', 'was', 'above', 'is', \"haven't\", 'by', 'there', 'hadn', 'when', 'me', 'should', 'does', 'he', 'once', 'of', \"don't\", \"wasn't\", 'each', 'no', 'wasn', 'i', 'against', 'isn', \"you'd\", 'mustn', \"mustn't\", \"you've\", 'they', 'any', 'most', 'under', 'needn', 'she', 'wouldn', 'some', 'yourselves', 'its', 'theirs', 'are', 'nor', 're', 'having', \"needn't\", 'hasn', 'other', 'do', 'been', 'after', 'we', 'my', 'in', 'ours', \"she's\", 'their', \"shouldn't\", 'mightn', 'a', 'now', 'haven', 'here', \"shan't\", 'not', 'or', 'don', 'aren', 'own', 'below', 'off', 'such', 'you', 'just', 'doesn', 'itself', 'can', 'd', \"you'll\", 'o', 'ain', \"you're\", 'shouldn', 'be', 'ma', 'to', 'with', 'and', 'won', 'then', 'had', 'if', 'very', 'between', 'shan', 's', 'again', 'through', \"doesn't\", 'myself', 'from', 'only', 'same', 'as', 'it', 'have', 've', 'which', 'few', 'these', \"couldn't\", \"should've\", 'but', 'too', \"hasn't\", \"that'll\", 'until', 'am', 'this', 'further', 'them', 'whom', 'doing', 'herself', 'where', 'during', 'hers', 'over', 'ourselves', 'will', 'your', 'y', \"hadn't\", 'on', 'the', \"isn't\", 'than', 'll', 'an', 'all', 'because', 'that', \"didn't\", 'yours', 'weren', 'more', 'why', \"weren't\", 'both', \"aren't\", 'while', 'him', 'themselves', \"mightn't\", 'up', 'couldn', 'about', 'into'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(stopwords_en)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jujqjOOW81Mb",
        "outputId": "87f4091b-c76b-4dfe-dc56-907dffe0727f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(stopwords_en)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztyfFqMC0s7N",
        "outputId": "4a70bc3a-2803-4088-f4c8-2fc501d254c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_text_filtered1 = []\n",
        "\n",
        "for item in word_text:\n",
        "  temp=[]\n",
        "  for word in item:\n",
        "    if word not in stopwords_en:\n",
        "        #print(word)\n",
        "        temp.append(word)\n",
        "  if(len(temp) != 0):\n",
        "    word_text_filtered1.append(temp)\n"
      ],
      "metadata": {
        "id": "9Pi9vHcF81J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_text_filtered1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xF2FghwpxARq",
        "outputId": "cd58c298-1534-49a8-d7e3-bca6e13d292b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287869"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_text_filtered1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-P2X8uLzMwx",
        "outputId": "7591dbe9-8c5b-4447-9eb4-4c90f1e4d0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hope'],\n",
              " ['okay'],\n",
              " ['let', \"'s\", 'go'],\n",
              " ['wow'],\n",
              " ['okay', 'gon', 'na', 'need', 'learn', 'lie'],\n",
              " ['kidding', 'know', 'sometimes', 'become', 'persona', 'know', 'quit'],\n",
              " ['like', 'fear', 'wearing', 'pastels'],\n",
              " ['real'],\n",
              " ['good', 'stuff'],\n",
              " ['figured', 'would', 'get', 'good', 'stuff', 'eventually']]"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "go7PgZhOzV5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list of stop words and remove them the original file."
      ],
      "metadata": {
        "id": "R8ouajkXrtfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "line = open('stopwords.txt', 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "MPQXYrJnzklf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line1 = open('stopwords_v2.txt', 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "nJ4KvDyH_Ky0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_words = {\" \"}\n",
        "for l1 in line1:\n",
        "  st_words.add(l1)\n"
      ],
      "metadata": {
        "id": "nZUaN0cU-aNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in line[:2]:\n",
        "  print(item)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB9eEOoWzkiX",
        "outputId": "59e00b7e-58b1-43f4-d228-5104377572dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(st_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvK9PjgyHeBD",
        "outputId": "9dce4ebb-bea5-4071-ae7a-3f34d610ee69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "st_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0WCE0IjJing",
        "outputId": "1dcce27b-d415-48ee-ef5f-f3f78eef910f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'',\n",
              " ' ',\n",
              " \"'insurance\",\n",
              " 'armymy',\n",
              " 'bullshitover',\n",
              " 'bureausembassies',\n",
              " 'deadhe',\n",
              " 'gentlemenii',\n",
              " 'inspiredmakes',\n",
              " 'jibbiting',\n",
              " 'listenif',\n",
              " 'mayst',\n",
              " 'togetherwe',\n",
              " 'ufutureu',\n",
              " 'whatsay'}"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_text_filtered1[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twBGwiTSxjqd",
        "outputId": "b38d90f0-9bf0-4a7a-f181-cea1f2fb0a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hope'],\n",
              " ['okay'],\n",
              " ['let', \"'s\", 'go'],\n",
              " ['wow'],\n",
              " ['okay', 'gon', 'na', 'need', 'learn', 'lie']]"
            ]
          },
          "metadata": {},
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U17693wtTHuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize"
      ],
      "metadata": {
        "id": "OS8aKWf0xhIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7b0560-af7b-4cba-8cd4-3c348431d2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function nltk.tokenize.word_tokenize(text, language='english', preserve_line=False)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_text_filtered1[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bXRYjnJAmC8",
        "outputId": "8e6772d3-ca76-4928-b16a-a845cef0e54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['hope'],\n",
              " ['okay'],\n",
              " ['let', \"'s\", 'go'],\n",
              " ['wow'],\n",
              " ['okay', 'gon', 'na', 'need', 'learn', 'lie'],\n",
              " ['kidding', 'know', 'sometimes', 'become', 'persona', 'know', 'quit'],\n",
              " ['like', 'fear', 'wearing', 'pastels'],\n",
              " ['real'],\n",
              " ['good', 'stuff'],\n",
              " ['figured', 'would', 'get', 'good', 'stuff', 'eventually']]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple iterations of stop word removal was performed over the original file and the file \"clean_text_whitelisted_removal_18_v3.txt\" is the final file on which the model would be trained."
      ],
      "metadata": {
        "id": "O7xywujrsene"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_MVrg-hI9Ow",
        "outputId": "79e1da95-ed04-40ed-89dd-03ba8d5e9ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5329696\n",
            "-rw-r--r-- 1 root root    9360275 Nov 17 11:24 clean_text_stop_word_removed.txt\n",
            "-rw-r--r-- 1 root root   16312686 Nov 17 12:48 clean_text_whitelisted1.txt\n",
            "-rw-r--r-- 1 root root    9016168 Nov 17 20:40 clean_text_whitelisted_removal_18.txt\n",
            "-rw-r--r-- 1 root root    9006819 Nov 17 21:10 clean_text_whitelisted_removal_18_v1.txt\n",
            "-rw-r--r-- 1 root root   15073934 Nov 17 21:24 clean_text_whitelisted_removal_18_v2.txt\n",
            "-rw-r--r-- 1 root root    9006671 Nov 17 21:33 clean_text_whitelisted_removal_18_v3.txt\n",
            "-rw-r--r-- 1 root root   16346490 Nov 17 11:11 clean_text_whitelisted.txt\n",
            "drwx------ 5 root root       4096 Nov 17 14:37 \u001b[0m\u001b[01;34mdrive\u001b[0m/\n",
            "-rw-rw-r-- 1 root root 1021669379 Aug 14  2014 glove.twitter.27B.100d.txt\n",
            "-rw-rw-r-- 1 root root 2057590469 Aug 14  2014 glove.twitter.27B.200d.txt\n",
            "-r--r--r-- 1 root root  257699726 Aug 14  2014 glove.twitter.27B.25d.txt\n",
            "-rw-rw-r-- 1 root root  510887943 Aug 14  2014 glove.twitter.27B.50d.txt\n",
            "-rw-r--r-- 1 root root 1520408563 Nov 17 10:33 glove.twitter.27B.zip\n",
            "drwxr-xr-x 1 root root       4096 Nov 15 14:30 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root     333869 Nov 17 17:56 stopwords.txt\n",
            "-rw-r--r-- 1 root root     354499 Nov 17 21:05 stopwords_v1.txt\n",
            "-rw-r--r-- 1 root root        134 Nov 17 21:16 stopwords_v2.txt\n",
            "-rw-r--r-- 1 root root        374 Nov 17 17:43 word-glove-context.npy\n",
            "-rw-r--r-- 1 root root    1397356 Nov 17 13:22 word-glove-target-idx2word.npy\n",
            "-rw-r--r-- 1 root root     839021 Nov 17 20:54 word-glove-target-idx2word_v1.npy\n",
            "-rw-r--r-- 1 root root    1397356 Nov 17 13:22 word-glove-target-word2idx.npy\n",
            "-rw-r--r-- 1 root root     839021 Nov 17 20:54 word-glove-target-word2idx_v1.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing a new version of Keras as the Tokenizer was not working in version\n",
        "2.1.2"
      ],
      "metadata": {
        "id": "tPRTSKOduFUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "JC2uL0HKJOpG",
        "outputId": "d580f8cc-08aa-4af9-9085-f2f654928629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.14.0\n",
            "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.6/1.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.1.2\n",
            "    Uninstalling Keras-2.1.2:\n",
            "      Successfully uninstalled Keras-2.1.2\n",
            "Successfully installed keras-2.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "qzDhVhZTBXSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TextLineDataset(['clean_text_whitelisted_removal_18.txt'])"
      ],
      "metadata": {
        "id": "p5tmyP-iBT-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_new = tf.keras.preprocessing.text.Tokenizer()"
      ],
      "metadata": {
        "id": "fgBNtauRBT67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_new.fit_on_texts([n.numpy().decode(\"utf-8\")for n in list(dataset.map(lambda x: x))])"
      ],
      "metadata": {
        "id": "LoiTzNViCfjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(x):\n",
        "  return tokenizer_new.texts_to_sequences(x)\n"
      ],
      "metadata": {
        "id": "v8AZjDOYCfgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize1(x):\n",
        "  return tokenizer_new.sequences_to_texts(x)"
      ],
      "metadata": {
        "id": "N0nENmf0Cfdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(['I believe we share an art instructor','90210'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlEsSRlZKVSd",
        "outputId": "c90579d4-0948-4096-d7f4-966602425c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[81, 914, 865, 14498], []]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(['START','start'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-JLYZ1L8y2S",
        "outputId": "0d5d4234-2f2b-4dd1-ef53-1bd9a788bb1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[194], [194]]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize1([[14218, 1053, 85, 1088, 23, 180, 2],[2, 180]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz-lGUwFKVQY",
        "outputId": "87e79a3c-693c-4dcc-e4ca-f415540d4c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"hopping definitely years faith back miss 's\", \"'s miss\"]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx = {}\n",
        "target_idx2word = {}"
      ],
      "metadata": {
        "id": "QenBT6f_KVM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9I9b0IKSQ8Y",
        "outputId": "2c0be87e-b4da-4e98-ff0b-b2dd796356bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH1 = 'clean_text_whitelisted_removal_18_v3.txt'\n",
        "\n",
        "lines3 = open(DATA_PATH1, 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "Lq_uSi4-Wo6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNx0uMzDLfQF",
        "outputId": "b78c4b90-b46d-4ae4-e0bb-6413aa562d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 5329696\n",
            "-rw-r--r-- 1 root root    9360275 Nov 17 11:24 clean_text_stop_word_removed.txt\n",
            "-rw-r--r-- 1 root root   16312686 Nov 17 12:48 clean_text_whitelisted1.txt\n",
            "-rw-r--r-- 1 root root    9016168 Nov 17 20:40 clean_text_whitelisted_removal_18.txt\n",
            "-rw-r--r-- 1 root root    9006819 Nov 17 21:10 clean_text_whitelisted_removal_18_v1.txt\n",
            "-rw-r--r-- 1 root root   15073934 Nov 17 21:24 clean_text_whitelisted_removal_18_v2.txt\n",
            "-rw-r--r-- 1 root root    9006662 Nov 17 21:44 clean_text_whitelisted_removal_18_v3.txt\n",
            "-rw-r--r-- 1 root root   16346490 Nov 17 11:11 clean_text_whitelisted.txt\n",
            "drwx------ 5 root root       4096 Nov 17 14:37 \u001b[0m\u001b[01;34mdrive\u001b[0m/\n",
            "-rw-rw-r-- 1 root root 1021669379 Aug 14  2014 glove.twitter.27B.100d.txt\n",
            "-rw-rw-r-- 1 root root 2057590469 Aug 14  2014 glove.twitter.27B.200d.txt\n",
            "-r--r--r-- 1 root root  257699726 Aug 14  2014 glove.twitter.27B.25d.txt\n",
            "-rw-rw-r-- 1 root root  510887943 Aug 14  2014 glove.twitter.27B.50d.txt\n",
            "-rw-r--r-- 1 root root 1520408563 Nov 17 10:33 glove.twitter.27B.zip\n",
            "drwxr-xr-x 1 root root       4096 Nov 15 14:30 \u001b[01;34msample_data\u001b[0m/\n",
            "-rw-r--r-- 1 root root     333869 Nov 17 17:56 stopwords.txt\n",
            "-rw-r--r-- 1 root root     354499 Nov 17 21:05 stopwords_v1.txt\n",
            "-rw-r--r-- 1 root root        134 Nov 17 21:16 stopwords_v2.txt\n",
            "-rw-r--r-- 1 root root        374 Nov 17 17:43 word-glove-context.npy\n",
            "-rw-r--r-- 1 root root    1397356 Nov 17 13:22 word-glove-target-idx2word.npy\n",
            "-rw-r--r-- 1 root root     839021 Nov 17 20:54 word-glove-target-idx2word_v1.npy\n",
            "-rw-r--r-- 1 root root    1397356 Nov 17 13:22 word-glove-target-word2idx.npy\n",
            "-rw-r--r-- 1 root root     839021 Nov 17 20:54 word-glove-target-word2idx_v1.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a dictionary which would do the mapping between string words to an integer id and reverse as well.\n",
        "\n"
      ],
      "metadata": {
        "id": "cSXOP834vBRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx = {}\n",
        "target_idx2word = {}"
      ],
      "metadata": {
        "id": "zdINUPHWLfNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for line in lines3:\n",
        "  #print(line)\n",
        "  word_text = word_tokenize(line)\n",
        "  word_text = line.split()\n",
        "  #print (word_text)\n",
        "  #print(word_text)\n",
        "\n",
        "  for item in word_text:\n",
        "    #print(item)\n",
        "    #item = clean_text(item)\n",
        "    #print(item)\n",
        "\n",
        "\n",
        "    if(item == \"\"):\n",
        "      print(\"na\")\n",
        "      continue\n",
        "\n",
        "    lis1 = []\n",
        "    lis1.append(item)\n",
        "    #print(\"item\",item)\n",
        "    try:\n",
        "      value = tokenize(lis1)[0][0]\n",
        "    except:\n",
        "      print(word_text)\n",
        "    #print(tokenize(lis1))\n",
        "    target_word2idx[item] = value\n",
        "    target_idx2word[value] = item"
      ],
      "metadata": {
        "id": "AWSTFmNYKVKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx['run']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UMTZMlvKVHx",
        "outputId": "8ac1cfc0-984a-421f-8673-2bcb7462925a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "190"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_idx2word[284]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DWuZdPmSKVFP",
        "outputId": "e7d98cff-0c8e-4a7d-d735-3cea9ff0758c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'brother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0WJhlx0XgbF",
        "outputId": "bc464adf-76ce-4542-e393-1b6070c8094f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40780"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_idx2word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LqM1O9aXgX8",
        "outputId": "e15a2d65-a1dc-418b-da7a-ef5beeaa55a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40780"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines3 = open('clean_text_whitelisted_removal_18_v3.txt', 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "UMxUnM4Kpfkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary for the frequency of the vocabulary\n",
        "vocab = {}\n",
        "for line in lines3:\n",
        "    for word in line.split():\n",
        "        if word not in vocab:\n",
        "            vocab[word] = 1\n",
        "        else:\n",
        "            vocab[word] += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "xBv1FnzZoPlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze7PfFuvoPkO",
        "outputId": "7c5ac8d5-57fb-4705-f4a4-ee5bd35330b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40780"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab['luther']"
      ],
      "metadata": {
        "id": "kZ-APk7YXgVJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00de7e3-466f-45bb-acf6-edc043ac9989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The current vocabulary has 40780 words which is too high to train the model with current resources. So we are selectively considering only those items in the vocabulary which are repeated atleast 11 times.\n",
        "\n",
        "And the new vocabulary would be of 9742 words ( including 'START' and 'END' special keyword ).\n",
        "\n",
        "target_word2idx_new1  == Word to ID mapping\n",
        "target_idx2word_new1 == ID to word mapping."
      ],
      "metadata": {
        "id": "7tOBNfgAzyoN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIetLiI_zyPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test=[]\n",
        "\n",
        "for key,value in vocab.items():\n",
        "  if value < 11:\n",
        "    test.append(key)\n"
      ],
      "metadata": {
        "id": "RL9TBw19rl2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6VDQTtBrltb",
        "outputId": "9ed94ccf-53fc-4ecd-fc5c-d4ec635b5802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31040"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDvPlQozxXJR",
        "outputId": "2e5c9b1c-311a-462f-ac4b-b75129e08564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['persona',\n",
              " 'pastels',\n",
              " 'coiffure',\n",
              " 'babble',\n",
              " 'guillermo',\n",
              " 'instructor',\n",
              " 'chastity',\n",
              " 'jared',\n",
              " 'leto',\n",
              " 'harboring']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = set(test)"
      ],
      "metadata": {
        "id": "qUoGwlD7wVYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcqNa21Nwbdg",
        "outputId": "865648a5-5941-498f-e60f-1f24623ed500"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "set"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ3El-UqweDL",
        "outputId": "dc3c4035-d408-4d45-d4a0-29f97fa1df24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31040"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new = target_word2idx\n",
        "target_idx2word_new = target_idx2word"
      ],
      "metadata": {
        "id": "dpyEgyQjrlrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new1 ={}\n",
        "target_idx2word_new1 ={}"
      ],
      "metadata": {
        "id": "f1ATLEydxtHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key,value in target_word2idx_new.items():\n",
        "    if (key not in test_set):\n",
        "      target_word2idx_new1[key]=value\n",
        "      target_idx2word_new1[value]=key\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jwY3QIisu0nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_word2idx_new1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzI8dggdyyFx",
        "outputId": "bf5640f3-a5d4-4394-e4ea-7ac0e289ed84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9740"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_idx2word_new1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BON6nfOyyDL",
        "outputId": "6df128ca-b510-4e16-d37f-56d49cde3531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9740"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLUHRDFnEc6R",
        "outputId": "19f2ae49-217c-4782-d159-18022ccd3de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hope': 232,\n",
              " 'okay': 37,\n",
              " 'let': 24,\n",
              " \"'s\": 2,\n",
              " 'go': 11,\n",
              " 'wow': 820,\n",
              " 'gon': 40,\n",
              " 'na': 32,\n",
              " 'need': 44,\n",
              " 'learn': 521,\n",
              " 'lie': 495,\n",
              " 'kidding': 511,\n",
              " 'know': 1,\n",
              " 'sometimes': 348,\n",
              " 'become': 589,\n",
              " 'quit': 651,\n",
              " 'like': 4,\n",
              " 'fear': 773,\n",
              " 'wearing': 782,\n",
              " 'real': 126,\n",
              " 'good': 16,\n",
              " 'stuff': 198,\n",
              " 'figured': 654,\n",
              " 'would': 3,\n",
              " 'get': 5,\n",
              " 'eventually': 2019,\n",
              " 'thank': 114,\n",
              " 'god': 80,\n",
              " 'hear': 124,\n",
              " 'one': 9,\n",
              " 'story': 255,\n",
              " 'endless': 6962,\n",
              " 'blonde': 2143,\n",
              " 'boring': 1577,\n",
              " 'crap': 944,\n",
              " 'listen': 127,\n",
              " 'says': 182,\n",
              " 'lighter': 5823,\n",
              " 'look': 27,\n",
              " 'extra': 1198,\n",
              " 'always': 77,\n",
              " 'selfish': 3312,\n",
              " 'say': 25,\n",
              " 'well': 12,\n",
              " 'never': 31,\n",
              " 'wanted': 130,\n",
              " 'looked': 505,\n",
              " 'back': 23,\n",
              " 'party': 374,\n",
              " 'seemed': 1041,\n",
              " 'occupied': 6217,\n",
              " 'tons': 4177,\n",
              " 'fun': 452,\n",
              " 'tonight': 166,\n",
              " 'believe': 81,\n",
              " 'share': 914,\n",
              " 'art': 865,\n",
              " 'looks': 236,\n",
              " 'things': 65,\n",
              " 'worked': 518,\n",
              " 'huh': 141,\n",
              " 'hi': 243,\n",
              " 'knows': 238,\n",
              " 'ever': 57,\n",
              " 'heard': 161,\n",
              " 'dip': 6218,\n",
              " 'dating': 2687,\n",
              " 'guy': 73,\n",
              " 'smokes': 5066,\n",
              " 'kind': 101,\n",
              " 'likes': 771,\n",
              " 'pretty': 173,\n",
              " 'ones': 622,\n",
              " 'lesbian': 6467,\n",
              " 'found': 181,\n",
              " 'picture': 509,\n",
              " 'drawers': 8270,\n",
              " 'sure': 39,\n",
              " 'working': 245,\n",
              " 'seem': 431,\n",
              " 'going': 13,\n",
              " 'really': 36,\n",
              " 'wan': 246,\n",
              " 'unless': 558,\n",
              " 'sister': 463,\n",
              " 'goes': 345,\n",
              " 'deep': 774,\n",
              " 'every': 120,\n",
              " 'two': 47,\n",
              " 'days': 206,\n",
              " 'use': 197,\n",
              " 'without': 185,\n",
              " 'hair': 502,\n",
              " 'sweet': 583,\n",
              " 'word': 256,\n",
              " 'gentleman': 1438,\n",
              " 'counted': 5650,\n",
              " 'help': 74,\n",
              " 'cause': 465,\n",
              " 'obviously': 1094,\n",
              " 'failing': 7225,\n",
              " 'date': 576,\n",
              " 'got': 6,\n",
              " 'something': 28,\n",
              " 'mind': 135,\n",
              " 'someone': 133,\n",
              " 'think': 8,\n",
              " 'might': 111,\n",
              " 'little': 38,\n",
              " 'find': 60,\n",
              " 'plan': 479,\n",
              " 'forget': 226,\n",
              " 'french': 857,\n",
              " 'nice': 131,\n",
              " 'want': 7,\n",
              " 'though': 369,\n",
              " 'useful': 2844,\n",
              " 'stores': 4582,\n",
              " 'much': 48,\n",
              " 'champagne': 2144,\n",
              " 'cost': 861,\n",
              " 'chat': 2726,\n",
              " 'life': 59,\n",
              " 'point': 237,\n",
              " 'head': 186,\n",
              " 'right': 10,\n",
              " 'see': 14,\n",
              " 'ready': 274,\n",
              " 'gosh': 2297,\n",
              " 'could': 18,\n",
              " 'kat': 4085,\n",
              " 'boyfriend': 985,\n",
              " 'shame': 1604,\n",
              " 'unsolved': 8703,\n",
              " 'mystery': 2298,\n",
              " 'used': 169,\n",
              " 'popular': 2170,\n",
              " 'started': 403,\n",
              " 'high': 395,\n",
              " 'school': 220,\n",
              " 'sick': 375,\n",
              " 'seems': 418,\n",
              " 'easy': 301,\n",
              " 'enough': 129,\n",
              " 'thing': 41,\n",
              " 'cameron': 5494,\n",
              " 'mercy': 2889,\n",
              " 'particularly': 2360,\n",
              " 'hideous': 7530,\n",
              " 'breed': 5349,\n",
              " 'loser': 1938,\n",
              " 'fault': 595,\n",
              " 'proper': 1762,\n",
              " 'introduction': 8271,\n",
              " 'asking': 432,\n",
              " 'cute': 1020,\n",
              " 'name': 88,\n",
              " 'try': 152,\n",
              " 'saturday': 1335,\n",
              " 'night': 63,\n",
              " 'spitting': 7878,\n",
              " 'part': 235,\n",
              " 'please': 84,\n",
              " 'thought': 56,\n",
              " 'start': 194,\n",
              " 'make': 35,\n",
              " 'quick': 795,\n",
              " 'andrew': 3492,\n",
              " 'barrett': 7531,\n",
              " 'incredibly': 3556,\n",
              " 'public': 832,\n",
              " 'break': 372,\n",
              " \"'\": 64,\n",
              " 'prom': 2145,\n",
              " 'home': 96,\n",
              " 'twenty': 389,\n",
              " 'minutes': 248,\n",
              " 'give': 50,\n",
              " 'private': 663,\n",
              " 'line': 408,\n",
              " 'joey': 1456,\n",
              " 'wonder': 566,\n",
              " 'guys': 158,\n",
              " 'supposed': 249,\n",
              " 'actually': 283,\n",
              " 'bianca': 5824,\n",
              " 'include': 4086,\n",
              " 'combination': 3411,\n",
              " 'different': 307,\n",
              " 'dry': 1400,\n",
              " 'practically': 1737,\n",
              " 'proposed': 4278,\n",
              " 'mean': 33,\n",
              " 'dr': 303,\n",
              " 'great': 94,\n",
              " 'exactly': 242,\n",
              " 'relevant': 6963,\n",
              " 'conversation': 1299,\n",
              " 'getting': 122,\n",
              " 'drink': 296,\n",
              " 'change': 331,\n",
              " 'deal': 227,\n",
              " 'talk': 54,\n",
              " 'concentrating': 8272,\n",
              " 'awfully': 2795,\n",
              " 'hard': 216,\n",
              " 'considering': 2379,\n",
              " 'gym': 5350,\n",
              " 'class': 648,\n",
              " 'hey': 79,\n",
              " 'cheeks': 6964,\n",
              " 'agent': 670,\n",
              " 'shot': 317,\n",
              " 'next': 171,\n",
              " 'year': 262,\n",
              " 'neat': 2975,\n",
              " 'gay': 2020,\n",
              " 'cruise': 5651,\n",
              " 'uniform': 2224,\n",
              " 'queen': 1320,\n",
              " 'harry': 480,\n",
              " 'yeah': 19,\n",
              " 'tube': 4178,\n",
              " 'sock': 6014,\n",
              " 'gig': 3361,\n",
              " 'huge': 1763,\n",
              " 'ad': 2976,\n",
              " 'week': 268,\n",
              " 'hopefully': 5204,\n",
              " 'expensive': 2071,\n",
              " 'patrick': 2118,\n",
              " 'woman': 193,\n",
              " 'complete': 1114,\n",
              " 'completely': 699,\n",
              " 'damage': 1482,\n",
              " 'send': 378,\n",
              " 'therapy': 2361,\n",
              " 'forever': 896,\n",
              " 'set': 327,\n",
              " 'beautiful': 289,\n",
              " 'last': 75,\n",
              " 'guess': 110,\n",
              " 'experiences': 5825,\n",
              " 'trust': 338,\n",
              " 'people': 42,\n",
              " 'keep': 92,\n",
              " 'locked': 1042,\n",
              " 'away': 86,\n",
              " 'dark': 568,\n",
              " 'experience': 932,\n",
              " 'anything': 51,\n",
              " 'protecting': 2727,\n",
              " 'stupid': 406,\n",
              " 'repeat': 1795,\n",
              " 'mistakes': 2509,\n",
              " 'decisions': 3834,\n",
              " 'instead': 755,\n",
              " 'helping': 1411,\n",
              " 'daddy': 390,\n",
              " 'hold': 244,\n",
              " 'hostage': 3362,\n",
              " 'tell': 20,\n",
              " 'swore': 3686,\n",
              " 'everyone': 330,\n",
              " 'else': 123,\n",
              " 'since': 196,\n",
              " 'except': 541,\n",
              " 'display': 3687,\n",
              " 'afterwards': 3412,\n",
              " 'told': 72,\n",
              " 'anymore': 336,\n",
              " 'pissed': 1434,\n",
              " 'broke': 677,\n",
              " 'said': 43,\n",
              " 'hate': 313,\n",
              " 'total': 1446,\n",
              " 'babe': 1558,\n",
              " 'month': 609,\n",
              " 'went': 159,\n",
              " 'wish': 323,\n",
              " 'luxury': 6712,\n",
              " 'asked': 318,\n",
              " 'care': 147,\n",
              " 'firm': 1906,\n",
              " 'believer': 8273,\n",
              " 'reasons': 1578,\n",
              " 'sit': 288,\n",
              " 'susie': 2362,\n",
              " 'welcome': 706,\n",
              " 'act': 527,\n",
              " 'totally': 785,\n",
              " 'social': 1709,\n",
              " 'advice': 1077,\n",
              " 'freak': 1661,\n",
              " 'friend': 165,\n",
              " 'allowed': 1457,\n",
              " 'dead': 104,\n",
              " 'shakespeare': 3914,\n",
              " 'maybe': 45,\n",
              " 'even': 53,\n",
              " 'means': 358,\n",
              " 'least': 292,\n",
              " 'sucked': 3835,\n",
              " 'wretched': 6015,\n",
              " 'normal': 948,\n",
              " 'busy': 678,\n",
              " 'listening': 830,\n",
              " 'bitches': 4179,\n",
              " 'ruining': 4940,\n",
              " 'torture': 2728,\n",
              " 'suck': 1778,\n",
              " 'oh': 15,\n",
              " 'bothering': 2171,\n",
              " 'ask': 121,\n",
              " 'playing': 490,\n",
              " 'club': 851,\n",
              " 'skunk': 7226,\n",
              " 'becoming': 2249,\n",
              " 'bra': 5826,\n",
              " 'potential': 3156,\n",
              " 'smack': 5495,\n",
              " 'way': 34,\n",
              " 'nowhere': 1340,\n",
              " 'captain': 346,\n",
              " 'men': 191,\n",
              " 'missing': 806,\n",
              " 'fine': 132,\n",
              " 'prisoner': 3018,\n",
              " 'house': 138,\n",
              " 'daughter': 482,\n",
              " 'possession': 2568,\n",
              " 'end': 280,\n",
              " 'hot': 460,\n",
              " 'rod': 2764,\n",
              " 'whatever': 285,\n",
              " 'bend': 3253,\n",
              " 'rules': 1016,\n",
              " 'discuss': 1206,\n",
              " 'tomorrow': 188,\n",
              " 'scare': 1401,\n",
              " 'promise': 466,\n",
              " 'boys': 410,\n",
              " 'present': 821,\n",
              " 'minute': 215,\n",
              " 'wear': 617,\n",
              " 'belly': 3620,\n",
              " 'starting': 845,\n",
              " 'expect': 517,\n",
              " 'knew': 156,\n",
              " 'forbid': 6016,\n",
              " 'gloria': 4825,\n",
              " 'otherwise': 1207,\n",
              " 'known': 512,\n",
              " 'must': 70,\n",
              " 'attempting': 7532,\n",
              " 'small': 499,\n",
              " 'study': 1141,\n",
              " 'group': 1031,\n",
              " 'friends': 229,\n",
              " 'fair': 655,\n",
              " 'mutant': 6017,\n",
              " 'neither': 786,\n",
              " 'sleep': 293,\n",
              " 'starts': 1185,\n",
              " 'discussion': 3100,\n",
              " 'upset': 767,\n",
              " 'boy': 151,\n",
              " 'sent': 443,\n",
              " \"'em\": 170,\n",
              " 'girls': 454,\n",
              " 'tall': 2055,\n",
              " 'decent': 1828,\n",
              " 'body': 382,\n",
              " 'kinda': 671,\n",
              " 'short': 819,\n",
              " 'fan': 1811,\n",
              " 'couple': 325,\n",
              " 'minors': 8704,\n",
              " 'come': 21,\n",
              " 'pegged': 8705,\n",
              " 'ring': 775,\n",
              " 'pleasure': 796,\n",
              " 'best': 167,\n",
              " 'case': 230,\n",
              " 'scenario': 6713,\n",
              " 'payroll': 5496,\n",
              " 'awhile': 1505,\n",
              " 'humiliated': 6018,\n",
              " 'sacrifice': 3254,\n",
              " 'altar': 9177,\n",
              " 'dignity': 4583,\n",
              " 'score': 1924,\n",
              " 'making': 299,\n",
              " 'progress': 2446,\n",
              " 'hell': 91,\n",
              " 'picks': 4180,\n",
              " 'girl': 112,\n",
              " 'carries': 7227,\n",
              " 'talking': 100,\n",
              " 'extremely': 2056,\n",
              " 'unfortunate': 3157,\n",
              " 'maneuver': 7228,\n",
              " 'whole': 162,\n",
              " 'already': 200,\n",
              " 'favorite': 1071,\n",
              " 'band': 1362,\n",
              " 'ears': 1439,\n",
              " 'uncle': 691,\n",
              " 'lung': 5351,\n",
              " 'cancer': 1686,\n",
              " 'issue': 1623,\n",
              " 'number': 361,\n",
              " 'hates': 1726,\n",
              " 'piss': 1662,\n",
              " 'joy': 2796,\n",
              " 'ultimate': 4279,\n",
              " 'kiss': 688,\n",
              " 'ass': 265,\n",
              " 'bent': 4373,\n",
              " 'blow': 621,\n",
              " 'golden': 2688,\n",
              " 'opportunity': 1525,\n",
              " 'choice': 605,\n",
              " 'besides': 554,\n",
              " 'enemy': 1219,\n",
              " 'battle': 1764,\n",
              " 'position': 986,\n",
              " 'power': 405,\n",
              " 'pretend': 1543,\n",
              " 'calling': 497,\n",
              " 'shots': 2072,\n",
              " 'setting': 2478,\n",
              " 'time': 22,\n",
              " 'involved': 717,\n",
              " 'ta': 118,\n",
              " 'clients': 2921,\n",
              " 'wall': 910,\n",
              " 'street': 424,\n",
              " 'hated': 1596,\n",
              " 'strictly': 3557,\n",
              " 'side': 343,\n",
              " 'reputation': 1888,\n",
              " 'serious': 413,\n",
              " 'man': 30,\n",
              " 'whacked': 5652,\n",
              " 'sold': 1190,\n",
              " 'liver': 5352,\n",
              " 'black': 396,\n",
              " 'market': 1544,\n",
              " 'buy': 364,\n",
              " 'new': 98,\n",
              " 'honors': 7879,\n",
              " 'criminal': 1352,\n",
              " 'lit': 4493,\n",
              " 'state': 516,\n",
              " 'trooper': 8706,\n",
              " 'fire': 380,\n",
              " 'danger': 1152,\n",
              " 'makes': 250,\n",
              " 'unlikely': 6019,\n",
              " 'still': 62,\n",
              " 'teach': 887,\n",
              " 'charm': 3621,\n",
              " 'falls': 1939,\n",
              " 'love': 55,\n",
              " 'minor': 3019,\n",
              " 'encounter': 6468,\n",
              " 'chance': 310,\n",
              " 'signed': 1779,\n",
              " 'mom': 270,\n",
              " 'canada': 3762,\n",
              " 'moron': 3055,\n",
              " 'twelve': 709,\n",
              " 'model': 2363,\n",
              " 'mostly': 1300,\n",
              " 'regional': 8707,\n",
              " 'big': 97,\n",
              " 'coming': 146,\n",
              " 'bred': 8708,\n",
              " 'mothers': 3915,\n",
              " 'liked': 694,\n",
              " 'gene': 4696,\n",
              " 'pool': 1336,\n",
              " 'rarely': 5497,\n",
              " 'haircut': 4826,\n",
              " 'matter': 175,\n",
              " 'older': 1301,\n",
              " 'burn': 1212,\n",
              " 'pine': 7229,\n",
              " 'seen': 163,\n",
              " 'horse': 907,\n",
              " 'jack': 305,\n",
              " 'thousand': 287,\n",
              " 'evil': 757,\n",
              " 'many': 179,\n",
              " 'old': 89,\n",
              " 'cows': 5067,\n",
              " 'live': 168,\n",
              " 'north': 1072,\n",
              " 'dakota': 7880,\n",
              " \"c'mon\": 545,\n",
              " 'tour': 2197,\n",
              " 'worst': 1073,\n",
              " 'kissed': 2977,\n",
              " 'needs': 478,\n",
              " 'cool': 469,\n",
              " 'day': 83,\n",
              " 'direct': 1889,\n",
              " 'quote': 3413,\n",
              " 'decided': 787,\n",
              " 'nail': 2225,\n",
              " 'drunk': 720,\n",
              " 'remember': 103,\n",
              " 'partial': 6219,\n",
              " 'book': 397,\n",
              " 'around': 66,\n",
              " 'chicks': 3255,\n",
              " 'play': 199,\n",
              " 'instruments': 5653,\n",
              " 'food': 507,\n",
              " 'angry': 1007,\n",
              " 'music': 590,\n",
              " 'certain': 679,\n",
              " 'pieces': 1419,\n",
              " 'information': 591,\n",
              " 'miss': 180,\n",
              " 'helpful': 3363,\n",
              " 'non': 4374,\n",
              " 'type': 949,\n",
              " 'leave': 117,\n",
              " 'alone': 211,\n",
              " 'ya': 172,\n",
              " 'goin': 6965,\n",
              " 'running': 383,\n",
              " 'rest': 312,\n",
              " 'noticed': 1213,\n",
              " 'spread': 2540,\n",
              " 'elbow': 7881,\n",
              " 'tough': 707,\n",
              " 'reading': 877,\n",
              " 'barbie': 7882,\n",
              " 'ng': 8709,\n",
              " 'ken': 4584,\n",
              " 'shit': 87,\n",
              " 'flowers': 1545,\n",
              " 'another': 137,\n",
              " 'hundred': 201,\n",
              " 'human': 489,\n",
              " 'bucks': 684,\n",
              " 'price': 858,\n",
              " 'control': 513,\n",
              " 'acts': 4280,\n",
              " 'image': 2198,\n",
              " 'watching': 614,\n",
              " 'bitch': 519,\n",
              " 'trash': 3101,\n",
              " 'car': 150,\n",
              " 'count': 792,\n",
              " 'shell': 4087,\n",
              " 'fifty': 488,\n",
              " 'results': 3364,\n",
              " 'take': 29,\n",
              " 'negotiation': 7883,\n",
              " 'thirty': 603,\n",
              " 'gets': 300,\n",
              " 'catch': 524,\n",
              " 'pay': 275,\n",
              " 'verona': 7230,\n",
              " 'pick': 392,\n",
              " 'tab': 6469,\n",
              " 'cake': 2092,\n",
              " 'money': 69,\n",
              " 'legs': 1171,\n",
              " 'rack': 6020,\n",
              " 'higher': 2199,\n",
              " 'better': 71,\n",
              " 'fuck': 99,\n",
              " 'heavily': 6470,\n",
              " 'invested': 7533,\n",
              " 'took': 204,\n",
              " 'together': 195,\n",
              " 'kids': 267,\n",
              " 'uh': 149,\n",
              " 'recruit': 8710,\n",
              " 'job': 148,\n",
              " 'purpose': 1420,\n",
              " 'insane': 1115,\n",
              " 'run': 190,\n",
              " 'idea': 177,\n",
              " 'interested': 557,\n",
              " 'nope': 1321,\n",
              " 'came': 142,\n",
              " 'lost': 269,\n",
              " 'honey': 353,\n",
              " 'hallucinations': 8711,\n",
              " 'william': 1605,\n",
              " 'meet': 213,\n",
              " 'us': 26,\n",
              " 'looking': 153,\n",
              " 'wrong': 115,\n",
              " 'perspective': 5827,\n",
              " 'statement': 2057,\n",
              " 'dress': 853,\n",
              " 'anyway': 223,\n",
              " 'sound': 462,\n",
              " 'betty': 1043,\n",
              " 'archie': 6966,\n",
              " 'taking': 298,\n",
              " 'veronica': 2729,\n",
              " 'dates': 3313,\n",
              " 'imagine': 643,\n",
              " 'commercial': 3365,\n",
              " 'excess': 9178,\n",
              " 'rejected': 6471,\n",
              " 'favor': 685,\n",
              " 'done': 136,\n",
              " 'officially': 4375,\n",
              " 'opposed': 4376,\n",
              " 'activity': 3622,\n",
              " 'cares': 1363,\n",
              " 'work': 67,\n",
              " 'precious': 2510,\n",
              " 'appreciate': 822,\n",
              " 'efforts': 5498,\n",
              " 'toward': 1687,\n",
              " 'death': 316,\n",
              " 'proven': 5828,\n",
              " 'gone': 217,\n",
              " 'fit': 1036,\n",
              " 'sarah': 1859,\n",
              " 'lawrence': 7231,\n",
              " 'insists': 8712,\n",
              " 'puking': 9179,\n",
              " 'golf': 2623,\n",
              " 'team': 807,\n",
              " 'foul': 4377,\n",
              " 'sex': 493,\n",
              " 'realize': 739,\n",
              " 'institution': 3493,\n",
              " 'lacking': 7232,\n",
              " 'killing': 639,\n",
              " 'beyond': 1142,\n",
              " 'scope': 5829,\n",
              " 'teenage': 6714,\n",
              " 'far': 277,\n",
              " 'past': 551,\n",
              " 'daytime': 7884,\n",
              " 'show': 164,\n",
              " 'entering': 3414,\n",
              " 'world': 140,\n",
              " 'attempted': 6220,\n",
              " 'slit': 6221,\n",
              " 'eat': 319,\n",
              " 'starving': 3056,\n",
              " 'slow': 823,\n",
              " 'die': 239,\n",
              " 'block': 1699,\n",
              " 'e': 2797,\n",
              " 'incapable': 7534,\n",
              " 'interesting': 687,\n",
              " 'pat': 2922,\n",
              " 'porn': 5499,\n",
              " 'movies': 872,\n",
              " 'random': 3494,\n",
              " 'dare': 1829,\n",
              " 'freshman': 7885,\n",
              " 'burger': 4088,\n",
              " 'burnt': 5068,\n",
              " 'object': 2200,\n",
              " 'fucked': 623,\n",
              " 'fell': 1004,\n",
              " 'cash': 718,\n",
              " 'asshole': 727,\n",
              " 'paid': 619,\n",
              " 'fender': 8713,\n",
              " 'bought': 762,\n",
              " 'payment': 3158,\n",
              " 'bonus': 4378,\n",
              " 'sleeping': 996,\n",
              " 'person': 352,\n",
              " 'truly': 1322,\n",
              " 'setup': 3495,\n",
              " 'wait': 108,\n",
              " 'worse': 550,\n",
              " 'adorable': 4585,\n",
              " 'lived': 768,\n",
              " 'grandfather': 2093,\n",
              " 'died': 398,\n",
              " 'stayed': 1483,\n",
              " 'jail': 722,\n",
              " 'slept': 1710,\n",
              " 'spice': 4494,\n",
              " 'spent': 960,\n",
              " 'sitting': 610,\n",
              " 'grandma': 2299,\n",
              " 'couch': 3210,\n",
              " 'wheel': 1907,\n",
              " 'fortune': 1559,\n",
              " 'grandmother': 2596,\n",
              " 'sorry': 52,\n",
              " 'questioned': 4697,\n",
              " 'motives': 6967,\n",
              " 'convicted': 6472,\n",
              " 'nothing': 49,\n",
              " 'company': 494,\n",
              " 'answer': 376,\n",
              " 'question': 328,\n",
              " 'anyone': 231,\n",
              " 'motive': 3916,\n",
              " 'create': 1890,\n",
              " 'drama': 5500,\n",
              " 'rumor': 3995,\n",
              " 'tradition': 3623,\n",
              " 'request': 2073,\n",
              " 'command': 1100,\n",
              " 'sexy': 2511,\n",
              " 'true': 258,\n",
              " 'career': 1149,\n",
              " 'duck': 2798,\n",
              " 'disappointed': 3102,\n",
              " 'screwed': 2074,\n",
              " 'disappoint': 3996,\n",
              " 'covered': 1632,\n",
              " 'yes': 17,\n",
              " 'acting': 936,\n",
              " 'excuse': 370,\n",
              " 'soft': 1506,\n",
              " 'wit': 4586,\n",
              " 'call': 58,\n",
              " 'ridiculous': 1021,\n",
              " 'win': 641,\n",
              " 'respect': 697,\n",
              " 'family': 263,\n",
              " 'climb': 2075,\n",
              " 'staying': 758,\n",
              " 'put': 82,\n",
              " 'foot': 1181,\n",
              " 'angle': 2845,\n",
              " 'bad': 102,\n",
              " 'afraid': 234,\n",
              " 'heights': 5353,\n",
              " 'sunshine': 5205,\n",
              " 'left': 145,\n",
              " 'dickhead': 7535,\n",
              " 'effect': 2300,\n",
              " 'whatsoever': 5069,\n",
              " 'panties': 4698,\n",
              " 'twist': 4827,\n",
              " 'pleasant': 2648,\n",
              " 'poetry': 2978,\n",
              " 'copy': 1110,\n",
              " 'offense': 2094,\n",
              " 'wants': 221,\n",
              " 'dad': 214,\n",
              " 'pain': 747,\n",
              " 'strike': 1570,\n",
              " 'permission': 1940,\n",
              " 'father': 134,\n",
              " 'approve': 4699,\n",
              " 'saw': 154,\n",
              " 'wake': 713,\n",
              " 'laid': 1323,\n",
              " 'tequila': 7886,\n",
              " 'affection': 5830,\n",
              " 'blind': 1166,\n",
              " 'hatred': 6222,\n",
              " 'words': 508,\n",
              " 'concussion': 8714,\n",
              " 'dog': 445,\n",
              " 'woke': 1738,\n",
              " 'vegetable': 6223,\n",
              " 'difference': 644,\n",
              " 'funny': 347,\n",
              " 'kill': 107,\n",
              " 'sort': 385,\n",
              " 'depends': 1447,\n",
              " 'topic': 7536,\n",
              " 'whip': 3688,\n",
              " 'verbal': 6224,\n",
              " 'following': 1153,\n",
              " 'vomit': 4700,\n",
              " 'ponies': 8715,\n",
              " 'flat': 1891,\n",
              " 'beer': 873,\n",
              " 'eyes': 350,\n",
              " 'hand': 320,\n",
              " 'spend': 731,\n",
              " 'dollar': 987,\n",
              " 'track': 1186,\n",
              " 'warrant': 2649,\n",
              " 'strong': 814,\n",
              " 'emotion': 4701,\n",
              " 'lot': 106,\n",
              " 'places': 1074,\n",
              " 'friday': 1390,\n",
              " 'mission': 950,\n",
              " 'attention': 897,\n",
              " 'sweating': 4702,\n",
              " 'pig': 1507,\n",
              " 'christ': 384,\n",
              " 'changed': 650,\n",
              " 'check': 333,\n",
              " 'fathers': 5070,\n",
              " 'admit': 924,\n",
              " 'daughters': 4281,\n",
              " 'capable': 2095,\n",
              " 'lives': 458,\n",
              " 'lets': 1860,\n",
              " 'years': 85,\n",
              " 'able': 434,\n",
              " 'watch': 260,\n",
              " 'game': 367,\n",
              " 'impressed': 1941,\n",
              " 'rubbed': 8716,\n",
              " 'beat': 471,\n",
              " 'parts': 1739,\n",
              " 'dance': 719,\n",
              " 'understand': 109,\n",
              " 'hip': 3689,\n",
              " 'full': 427,\n",
              " 'sperm': 6473,\n",
              " 'east': 1373,\n",
              " 'coast': 1996,\n",
              " 'choices': 3057,\n",
              " 'eighteen': 1588,\n",
              " 'parent': 4941,\n",
              " 'agree': 1010,\n",
              " 'punishing': 8717,\n",
              " 'insurance': 1256,\n",
              " 'cover': 866,\n",
              " 'pms': 5354,\n",
              " 'whose': 951,\n",
              " 'diary': 4089,\n",
              " 'devoted': 5831,\n",
              " 'tips': 4090,\n",
              " 'u': 6225,\n",
              " 'feel': 95,\n",
              " 'term': 2730,\n",
              " 'often': 1056,\n",
              " 'somewhat': 5501,\n",
              " 'maintain': 4091,\n",
              " 'kicked': 1962,\n",
              " 'balls': 1435,\n",
              " 'merely': 3020,\n",
              " 'compared': 3836,\n",
              " 'expression': 3624,\n",
              " 'today': 212,\n",
              " 'events': 2650,\n",
              " 'quite': 326,\n",
              " 'bobby': 1044,\n",
              " 'retrieval': 6021,\n",
              " 'operation': 1471,\n",
              " 'opinion': 1249,\n",
              " 'terrorist': 5355,\n",
              " 'action': 1125,\n",
              " 'ms': 1676,\n",
              " 'pictures': 811,\n",
              " 'tired': 496,\n",
              " 'breathing': 1963,\n",
              " 'thy': 1942,\n",
              " 'force': 824,\n",
              " 'lose': 447,\n",
              " 'cozy': 5502,\n",
              " 'liking': 6022,\n",
              " 'prefer': 1484,\n",
              " 'simply': 1191,\n",
              " 'alternative': 4092,\n",
              " 'law': 616,\n",
              " 'allows': 6226,\n",
              " 'telling': 302,\n",
              " 'wild': 1078,\n",
              " 'beast': 2447,\n",
              " 'pawn': 6968,\n",
              " 'whoever': 1228,\n",
              " 'speak': 420,\n",
              " 'correctly': 7887,\n",
              " 'pure': 1727,\n",
              " 'chick': 1876,\n",
              " 'three': 119,\n",
              " 'tits': 2058,\n",
              " 'situation': 725,\n",
              " 'major': 599,\n",
              " 'jones': 1861,\n",
              " 'standing': 776,\n",
              " 'waiting': 355,\n",
              " 'title': 1997,\n",
              " 'benefits': 4828,\n",
              " 'package': 2569,\n",
              " 'slightly': 4181,\n",
              " 'psychotic': 4829,\n",
              " 'driving': 728,\n",
              " 'loss': 2267,\n",
              " 'absence': 5206,\n",
              " 'touch': 503,\n",
              " 'flu': 6715,\n",
              " 'feeling': 402,\n",
              " 'teeth': 1126,\n",
              " 'eating': 997,\n",
              " 'lunch': 689,\n",
              " 'exposed': 4182,\n",
              " 'missed': 840,\n",
              " 'absolutely': 563,\n",
              " 'happened': 128,\n",
              " 'ruth': 3625,\n",
              " 'kissing': 2923,\n",
              " 'happens': 446,\n",
              " 'keeps': 994,\n",
              " 'elbows': 7233,\n",
              " 'pirate': 2799,\n",
              " 'rather': 522,\n",
              " 'british': 1535,\n",
              " 'rear': 5356,\n",
              " 'admiral': 1172,\n",
              " 'jesus': 240,\n",
              " 'grab': 1288,\n",
              " 'sandwich': 3159,\n",
              " 'women': 388,\n",
              " 'country': 377,\n",
              " 'cry': 1257,\n",
              " 'microwave': 6474,\n",
              " 'also': 422,\n",
              " 'smell': 854,\n",
              " 'sea': 1084,\n",
              " 'smells': 1976,\n",
              " 'cunt': 3997,\n",
              " 'sign': 578,\n",
              " 'weeks': 472,\n",
              " 'ago': 205,\n",
              " 'near': 652,\n",
              " 'land': 703,\n",
              " 'crazy': 222,\n",
              " 'devil': 1127,\n",
              " 'child': 461,\n",
              " 'face': 259,\n",
              " 'ah': 394,\n",
              " 'harm': 1750,\n",
              " 'chicken': 1233,\n",
              " 'drinking': 1049,\n",
              " 'glory': 2651,\n",
              " 'spain': 5654,\n",
              " 'colon': 6969,\n",
              " 'bastard': 749,\n",
              " 'water': 368,\n",
              " 'barrels': 8274,\n",
              " 'heat': 1324,\n",
              " 'las': 3103,\n",
              " 'asia': 5503,\n",
              " 'west': 893,\n",
              " 'prove': 798,\n",
              " 'faith': 1088,\n",
              " 'consider': 1122,\n",
              " 'heresy': 8718,\n",
              " 'considered': 2226,\n",
              " 'choose': 1458,\n",
              " 'carpenter': 2846,\n",
              " 'son': 218,\n",
              " 'reveal': 5071,\n",
              " 'intended': 3690,\n",
              " 'waited': 1700,\n",
              " 'discovered': 2146,\n",
              " 'bring': 251,\n",
              " 'interests': 2301,\n",
              " 'gold': 855,\n",
              " 'trade': 1485,\n",
              " 'excellency': 4379,\n",
              " 'according': 1606,\n",
              " 'marco': 8275,\n",
              " 'polo': 6716,\n",
              " 'kingdom': 4093,\n",
              " 'china': 1830,\n",
              " 'richest': 6717,\n",
              " 'buildings': 3256,\n",
              " 'follow': 525,\n",
              " 'others': 559,\n",
              " 'settle': 1382,\n",
              " 'journey': 2512,\n",
              " 'risk': 1095,\n",
              " 'possible': 486,\n",
              " 'senor': 7888,\n",
              " 'experienced': 4380,\n",
              " 'concern': 1711,\n",
              " 'crew': 1105,\n",
              " 'willing': 1132,\n",
              " 'conscience': 2847,\n",
              " 'upon': 1302,\n",
              " 'judgment': 3917,\n",
              " 'ignore': 2765,\n",
              " 'calculations': 9180,\n",
              " 'earth': 572,\n",
              " 'approximately': 5357,\n",
              " 'leagues': 6475,\n",
              " 'ocean': 1831,\n",
              " 'unfortunately': 2337,\n",
              " 'precisely': 2848,\n",
              " 'opinions': 6718,\n",
              " 'familiar': 1440,\n",
              " 'voyage': 4830,\n",
              " 'six': 271,\n",
              " 'seven': 552,\n",
              " 'sailing': 3918,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new1['START'] = 9998\n",
        "target_idx2word_new1[9998] = 'START'\n",
        "\n",
        "target_word2idx_new1['END'] = 9999\n",
        "target_idx2word_new1[9999] = 'END'"
      ],
      "metadata": {
        "id": "JPuG7lw8Ec23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_idx2word_new1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg68DQUsE7Fz",
        "outputId": "ef122920-e955-4a0c-e6ca-02f19287dc90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9742"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_idx2word_new1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkafTBHlE9QU",
        "outputId": "6d1773fd-b839-47a0-e4a4-1470297e4dd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9742"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new1['START']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqg-IYyXDyGb",
        "outputId": "79a06ef9-525c-4e80-974e-cfb5dc94f0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9998"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_idx2word_new1[9998]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vpviBzzZDyDF",
        "outputId": "0f420a2d-0397-483b-fb42-32fdc4a3c71c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'START'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new1['start']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUz8KmozASQ2",
        "outputId": "46dab39e-0366-426c-df24-8a271d9a4f2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_word2idx_new1['end']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqPbklY3AgB1",
        "outputId": "43bb7a09-ae09-4b1b-e55f-2d59da1ef914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(target_word2idx_new)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHbRdt96u0lq",
        "outputId": "5a93cf3c-439c-4986-b53a-1ab8b14f959a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40780"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urrJEhvYu0ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbNmEonjPHTy",
        "outputId": "8c74eac4-9d8a-47db-add0-b254b6cb117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines3 = open('clean_text_whitelisted_removal_18_v3.txt', 'rt', encoding='utf8').read().split('\\n')"
      ],
      "metadata": {
        "id": "FGPnKNx2Ek97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FsdjO_jdcD_"
      },
      "outputs": [],
      "source": [
        "next_words=[]\n",
        "target_words=[]\n",
        "prev_words = []\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "\n",
        "\n",
        "for line in lines3:\n",
        "    next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
        "    #print(\"next_word\",next_words)\n",
        "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
        "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
        "    if len(prev_words) > 0:\n",
        "        input_texts.append(prev_words)\n",
        "        target_words = next_words[:]\n",
        "        #print(\"target\",target_words)\n",
        "        target_words.insert(0, 'START')\n",
        "        target_words.append('END')\n",
        "        for w in target_words:\n",
        "            target_counter[w] += 1\n",
        "        target_texts.append(target_words)\n",
        "    prev_words = next_words\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(\"******************************************\")\n",
        "    print(\"input:\",input_texts[i])\n",
        "    print(\"output:\",target_texts[i])\n",
        "    print(\"******************************************\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvQOQCYJQ4TN",
        "outputId": "f3447c2a-fdac-48e1-bec6-e6b0b8bdea30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************************\n",
            "input: ['hope']\n",
            "output: ['START', 'okay', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['okay']\n",
            "output: ['START', 'let', \"'s\", 'go', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['let', \"'s\", 'go']\n",
            "output: ['START', 'wow', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['wow']\n",
            "output: ['START', 'okay', 'gon', 'na', 'need', 'learn', 'lie', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['okay', 'gon', 'na', 'need', 'learn', 'lie']\n",
            "output: ['START', 'kidding', 'know', 'sometimes', 'become', 'persona', 'know', 'quit', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['kidding', 'know', 'sometimes', 'become', 'persona', 'know', 'quit']\n",
            "output: ['START', 'like', 'fear', 'wearing', 'pastels', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['like', 'fear', 'wearing', 'pastels']\n",
            "output: ['START', 'real', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['real']\n",
            "output: ['START', 'good', 'stuff', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['good', 'stuff']\n",
            "output: ['START', 'figured', 'would', 'get', 'good', 'stuff', 'eventually', 'END']\n",
            "******************************************\n",
            "******************************************\n",
            "input: ['figured', 'would', 'get', 'good', 'stuff', 'eventually']\n",
            "output: ['START', 'thank', 'god', 'hear', 'one', 'story', 'coiffure', 'END']\n",
            "******************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bt2fDiJfQ4QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcYFBgUIdcEF"
      },
      "source": [
        "Filter the conversations till max word length and convert the dialogues pairs into input text and target texts. Put **start** and **end** token to recognise the beginning and end of the sentence token.\n",
        "\n",
        "## Let's see some of the training examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiCxfQtBdcEG",
        "outputId": "3f99de85-8c83-453d-d4f5-1cd4582c64dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['hope'], ['START', 'okay', 'END']]\n",
            "[['okay'], ['START', 'let', \"'s\", 'go', 'END']]\n",
            "[['let', \"'s\", 'go'], ['START', 'wow', 'END']]\n",
            "[['wow'], ['START', 'okay', 'gon', 'na', 'need', 'learn', 'lie', 'END']]\n",
            "[['okay', 'gon', 'na', 'need', 'learn', 'lie'], ['START', 'kidding', 'know', 'sometimes', 'become', 'persona', 'know', 'quit', 'END']]\n",
            "[['kidding', 'know', 'sometimes', 'become', 'persona', 'know', 'quit'], ['START', 'like', 'fear', 'wearing', 'pastels', 'END']]\n",
            "[['like', 'fear', 'wearing', 'pastels'], ['START', 'real', 'END']]\n",
            "[['real'], ['START', 'good', 'stuff', 'END']]\n",
            "[['good', 'stuff'], ['START', 'figured', 'would', 'get', 'good', 'stuff', 'eventually', 'END']]\n",
            "[['figured', 'would', 'get', 'good', 'stuff', 'eventually'], ['START', 'thank', 'god', 'hear', 'one', 'story', 'coiffure', 'END']]\n",
            "[['thank', 'god', 'hear', 'one', 'story', 'coiffure'], ['START', 'endless', 'blonde', 'babble', 'like', 'boring', 'END']]\n"
          ]
        }
      ],
      "source": [
        "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
        "    if idx > 10:\n",
        "        break\n",
        "    print([input_words, target_words])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKxizS6dcEL"
      },
      "source": [
        "### Create two dictionaries\n",
        "<ol>\n",
        "<li>target_word2id\n",
        "<li>target_id2word\n",
        "</ol>\n",
        "and save it as NumPy file format in the disk.\n",
        "<p>\n",
        "<strong>NOTE:</strong> The ids should start from 1 beacause <strong>0</strong> is reserved for <strong>'unknown'</strong> tokens.\n",
        "Make sure you cosider only the <strong>most common</strong> tokens with <strong>MAX_VOCAB_SIZE</strong> defined above.\n",
        "\n",
        "Most common refers to tokens with higher frequency.\n",
        "</p>\n",
        "<strong>Help:</strong>\n",
        "<ol>\n",
        "<li>Use the target_counter which have the token counts.  \n",
        "<li>Use target_counter.most_common(MAX_VOCAB_SIZE) to filter common tokens\n",
        "    </ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dictionaries are already created in previous step .\n",
        "\n",
        "target_word2idx_new1 and target_idx2word_new1"
      ],
      "metadata": {
        "id": "Sy-0qYvN5etX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('word-glove-target-word2idx_v1.npy', target_word2idx_new1)\n",
        "np.save('word-glove-target-idx2word_v1.npy', target_idx2word_new1)"
      ],
      "metadata": {
        "id": "2pgwXGXVSxMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp word-glove-target-idx2word.npy /content/drive/MyDrive/INDUSTRY/"
      ],
      "metadata": {
        "id": "RhTfzymWcwQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp word-glove-target-word2idx.npy /content/drive/MyDrive/INDUSTRY/"
      ],
      "metadata": {
        "id": "0qSZ6E7EdnoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rI05RwJadtOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PzuUg4zdcER"
      },
      "source": [
        "# Check-2"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SGoSRxAkMv_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7pikaJfdcEU"
      },
      "outputs": [],
      "source": [
        "assert len (target_word2idx_new1.keys())==len (target_idx2word_new1.keys())<MAX_VOCAB_SIZE+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mw-Ly2xdcEc"
      },
      "source": [
        "# Prepare the input data with embedding\n",
        "The input data is a list of lists\n",
        "<ol>\n",
        "<li> First list is a list of sentences\n",
        "<li> Each sentence is a list of words\n",
        " </ol>\n",
        "\n",
        "input_texts_word2em = [{},{}...]\n",
        "This list contains the word embeddings of input words. Each item is an array which contains the embedded word mappings of corresponding words in each line of sentance.\n",
        "\n",
        "input_texts_word2em[0] ==> [arr1]\n",
        "\n",
        "arr1 represents the word embedding of 1st word of input text.\n",
        "\n",
        "Consider example:- 3rd sentence of input file.\n",
        "\n",
        "['let', \"'s\", 'go']\n",
        "\n",
        "len(input_texts_word2em[2]) => 3 means there are 3 words in input sentance 3.\n",
        "\n",
        "input_texts_word2em[2][0] => word embedding of 1st word of input sentance 3.\n",
        "\n",
        "input_texts_word2em[2][1] => word embedding of 2nd word of input sentance 3.\n",
        "\n",
        "input_texts_word2em[2][0] => word embedding of 3rd word of input sentance 3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoder_tokens = 9742\n",
        "\n"
      ],
      "metadata": {
        "id": "vyM9boa1TkYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cF423ayFRZu",
        "outputId": "5da5441b-7977-40c0-dac4-b2dfacc3808a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287869"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBmG1ea4dcEc",
        "outputId": "59f79dd2-98b2-4c84-c2a8-976b08974194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_decoder_tokens': 9742, 'encoder_max_seq_length': 40, 'decoder_max_seq_length': 42}\n"
          ]
        }
      ],
      "source": [
        "input_texts_word2em = []\n",
        "encoder_max_seq_length = 0\n",
        "decoder_max_seq_length = 0\n",
        "x = []\n",
        "\n",
        "for input_words, target_words in zip(input_texts, target_texts):\n",
        "    encoder_input_wids = []\n",
        "    for w in input_words:\n",
        "      try:\n",
        "        encoder_input_wids.append(word2embedding[w])\n",
        "      except:\n",
        "        x.append(w)\n",
        "\n",
        "\n",
        "    input_texts_word2em.append(encoder_input_wids)\n",
        "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
        "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
        "\n",
        "context = dict()\n",
        "context['num_decoder_tokens'] = num_decoder_tokens\n",
        "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
        "context['decoder_max_seq_length'] = decoder_max_seq_length\n",
        "\n",
        "print(context)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccr3CqNCbETw",
        "outputId": "0eebff46-0ff9-42fb-a81d-e8ea5a5b0c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b48gHKUdQe12",
        "outputId": "cb269daf-4633-4c8e-d944-e4bd6a7f909c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('word-glove-context_v1.npy', context)"
      ],
      "metadata": {
        "id": "oxVqP210Xh_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp word-glove-context.npy /content/drive/MyDrive/INDUSTRY/"
      ],
      "metadata": {
        "id": "evR2qYnpYc0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOXYWpJWYy0o",
        "outputId": "9c6d4a70-ab8b-4364-ff73-a84f0634b03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287869"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D-UtNCeF4z4",
        "outputId": "f693aab0-8d20-4170-b2cc-e188f9b9e9e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287869"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts_word2em)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WanYT9WDY2AE",
        "outputId": "f012cd29-238c-4c34-c0d3-36f0450bce3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "287869"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KBU8q0dZn4-",
        "outputId": "8036ad96-9023-4b69-c30e-8341fc74c2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_texts_word2em[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhFINjGbZtPH",
        "outputId": "0a0f68a2-9162-4c6e-ec2d-3ea7ab81ce77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGNthMi0UOAW",
        "outputId": "ef534fa9-038f-4f50-b69b-354a39e383d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hope']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts_word2em[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NCiCpH3Z5aj",
        "outputId": "3076b6bb-8730-415a-e4a9-663e9f060436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 0.096828,  0.96216 ,  0.26631 ,  0.1745  , -0.37467 ,  0.26376 ,\n",
              "         0.49862 , -0.074503,  0.10588 ,  0.27578 , -0.10256 ,  0.16923 ,\n",
              "        -4.7434  ,  0.4171  ,  0.086999,  0.031635,  0.3348  , -0.17257 ,\n",
              "        -0.516   ,  0.01793 ,  0.24739 , -0.35023 , -0.18885 ,  0.20731 ,\n",
              "         0.075228,  0.041435,  0.27558 ,  0.1194  ,  0.2924  , -0.4688  ,\n",
              "        -0.59928 ,  0.3397  , -0.055966,  0.30236 , -0.086538,  0.82669 ,\n",
              "         0.29416 , -0.44259 ,  0.45672 ,  0.33513 , -0.40102 ,  0.14918 ,\n",
              "        -0.07679 ,  0.11941 ,  0.042608,  0.18343 ,  0.29211 , -0.9592  ,\n",
              "        -0.13515 ,  0.39735 , -0.23312 , -0.31683 ,  0.35152 , -0.45224 ,\n",
              "         0.72213 ,  0.21249 , -0.20733 ,  0.52236 ,  0.37562 , -0.38926 ,\n",
              "         0.20423 , -0.14156 , -0.092994,  0.41954 , -0.056686,  0.03899 ,\n",
              "        -0.61005 , -0.32958 , -0.50119 , -0.28287 ,  0.38674 , -0.16925 ,\n",
              "         0.71155 ,  0.37228 ,  0.51185 ,  0.2022  ,  0.5125  , -0.1919  ,\n",
              "        -0.29209 , -0.076765,  1.7907  ,  0.17052 ,  0.26721 ,  0.30087 ,\n",
              "         0.32175 ,  0.1459  ,  0.33092 ,  0.061282, -0.12012 , -0.32352 ,\n",
              "         0.25737 , -0.40787 ,  0.4293  ,  0.31119 , -0.40749 , -0.3329  ,\n",
              "         0.14969 ,  0.073275,  0.15363 , -0.44924 ], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts_word2em[2][1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUv_t_SmRBr8",
        "outputId": "cf456a37-58d3-408a-abff-12db27c7a4e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(input_texts_word2em[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMYTkkwKHHVV",
        "outputId": "34e7ed69-7901-4c09-c6a4-056fe2fafaf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(input_texts_word2em[2][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AisW-SJfXvD9",
        "outputId": "c573d91a-8ecb-4a5e-b342-2e147d204359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fumc6ez1UVRr",
        "outputId": "76c7f04e-b3e7-4d6c-fb0a-47753157ec10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['START', 'okay', 'END']"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmeqQj75UVO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8IJeZVkdcEg"
      },
      "source": [
        "# Check-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXaPOQlddcEh"
      },
      "outputs": [],
      "source": [
        "for input_text,input_text_embed in zip (input_texts,range(len(input_texts_word2em))):\n",
        "    assert (len(input_text)==len(input_texts_word2em[input_text_embed]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DswrlYFk1FEy",
        "outputId": "5ba1fe22-833b-42c8-9e40-29e6cbb9d60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_max_seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI1UDJcf1FCT",
        "outputId": "20bfc564-102b-4a76-ba13-a7846a837838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GLOVE_EMBEDDING_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFSpvXKU1Jrp",
        "outputId": "ada8c5e8-cf41-4257-a10c-4f623973f815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE * encoder_max_seq_length * GLOVE_EMBEDDING_SIZE - BATCH_SIZE * GLOVE_EMBEDDING_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq-KgM3B1L1G",
        "outputId": "c9a6175f-4643-49da-c029-54c3be390cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124800"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXh-5WEUdcEn"
      },
      "source": [
        "# Generate Training data per batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvg8LBt-dcEo"
      },
      "source": [
        "generate_batch takes input embedding data (input_word2em_data) and target text data (target_texts) and returns trainable X and Y.\n",
        "X is a list of [X1,X2]\n",
        "where\n",
        "X1 is encoder_input_data_batch( which is created by putting the word embedding(glove vector) of the input tokens) padded in to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "X2 is decoder_input_data_batch which is created by putting the word embedding(glove vector) of the target_words tokens and padding it to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "Y is decoder_target_data_batch which is in shape of (BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens)\n",
        "which signifies for each target token text  in the batch we have an option of any token from the vocabularu to be the next predicted word"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_int_key = [ ]\n",
        "for key in target_idx2word_new1.keys():\n",
        "  vocab_int_key.append(key)\n"
      ],
      "metadata": {
        "id": "Z3YFBlA91DLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab_int_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6AJr09F17zb",
        "outputId": "ede98ed1-0c27-43dd-9444-1fe6d4f4ab11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9742"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_int_key_array = np.array(vocab_int_key)"
      ],
      "metadata": {
        "id": "8hGaBOES17yO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_int_key_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7jREssT3ATo",
        "outputId": "15429ac9-330f-44e0-8764-e78220173150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9742,)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_decoder_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwdZZBt23ASG",
        "outputId": "ead7b1b0-3f84-41af-a4bc-a555a5dd62ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9742"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context['num_decoder_tokens'] = 9742"
      ],
      "metadata": {
        "id": "YlVvhHdXQU2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37R_9qpHdcEp"
      },
      "outputs": [],
      "source": [
        "pad_constant = BATCH_SIZE * encoder_max_seq_length * GLOVE_EMBEDDING_SIZE - BATCH_SIZE * GLOVE_EMBEDDING_SIZE\n",
        "\n",
        "def generate_batch(input_word2em_data, output_text_data):\n",
        "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
        "\n",
        "    z = num_decoder_tokens * BATCH_SIZE * decoder_max_seq_length - len(vocab_int_key)\n",
        "\n",
        "\n",
        "    while True:\n",
        "\n",
        "        decoder_target_data_batch = np.pad(vocab_int_key_array, (0,z), 'constant', constant_values=(0, 0))\n",
        "        decoder_target_data_batch = decoder_target_data_batch.reshape(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens)\n",
        "\n",
        "\n",
        "        for batchIdx in range(0,num_batches):\n",
        "            start = batchIdx * BATCH_SIZE\n",
        "            end = (batchIdx + 1) * BATCH_SIZE\n",
        "            for i in range(start,end):\n",
        "                x = len(input_word2em_data[i])\n",
        "                x_t = len(input_word2em_data[i+1])\n",
        "                for j in range(0, x):\n",
        "                   if ( j == 0 ):\n",
        "                     temp_array = input_word2em_data[i][j]\n",
        "                   else:\n",
        "                     temp_array = np.append(temp_array, input_word2em_data[i][j])\n",
        "\n",
        "                for j_t in range(0,x_t):\n",
        "                  if ( j_t == 0 ):\n",
        "                     temp_array_t = input_word2em_data[i+1][j_t]\n",
        "                  else:\n",
        "                     temp_array_t = np.append(temp_array_t, input_word2em_data[i+1][j_t])\n",
        "\n",
        "\n",
        "\n",
        "                y = encoder_max_seq_length - x\n",
        "                y_t =  decoder_max_seq_length - x_t\n",
        "\n",
        "                pad_seq_arr = np.pad(temp_array, (0, y*100), 'constant', constant_values=(0, 0))\n",
        "                pad_seq_arr1 = pad_seq_arr.reshape(encoder_max_seq_length,GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "                pad_seq_arr_t = np.pad(temp_array_t, (0, y_t*100), 'constant', constant_values=(0, 0))\n",
        "                pad_seq_arr1_t = pad_seq_arr_t.reshape(decoder_max_seq_length,GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "                if ( i == start ):\n",
        "                  pad_batch_arr = pad_seq_arr1\n",
        "                  pad_batch_arr_t = pad_seq_arr1_t\n",
        "                else :\n",
        "                  pad_batch_arr = np.append(pad_batch_arr,pad_seq_arr1,axis=0)\n",
        "                  pad_batch_arr_t = np.append(pad_batch_arr_t,pad_seq_arr1_t,axis=0)\n",
        "\n",
        "\n",
        "            pad_batch_arr1 = pad_batch_arr.reshape(BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "            encoder_input_data_batch = pad_batch_arr1\n",
        "\n",
        "            pad_batch_arr1_t = pad_batch_arr_t.reshape(BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "            decoder_input_data_batch = pad_batch_arr1_t\n",
        "\n",
        "\n",
        "\n",
        "            #return(encoder_input_data_batch,decoder_input_data_batch,decoder_target_data_batch)\n",
        "\n",
        "\n",
        "        yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LlBf-WaV5az",
        "outputId": "ee4d37a1-66cb-424a-8011-f4d6bd4f2948"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen = generate_batch(input_texts_word2em,target_words)"
      ],
      "metadata": {
        "id": "hX5epMObOxdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_max_seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn7vc_2VJJLE",
        "outputId": "f2c62a9d-14aa-4633-bc52-b0529b65db04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O40SpQhL0JSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjnjiyidcEt"
      },
      "source": [
        "# Check-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assert statement below took too much time while running and run time crashed so i just tested based on few items generated from the yeild keyword and they passed fine so continuing further."
      ],
      "metadata": {
        "id": "RE5HPcUWFg9c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "4874c1ae-3f97-4853-df8a-c4c313a83572",
        "id": "GMSpAl1qFOXh"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-138-3f0e3f9ab8d4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts_word2em\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_gen\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder_max_seq_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGLOVE_EMBEDDING_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_max_seq_length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGLOVE_EMBEDDING_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-137-91020e6eeb60>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(input_word2em_data, output_text_data)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mpad_seq_arr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_seq_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_max_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGLOVE_EMBEDDING_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mpad_seq_arr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_array_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mpad_seq_arr1_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_seq_arr_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_max_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGLOVE_EMBEDDING_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    791\u001b[0m     \u001b[0;31m# Create array with final shape and original values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m     \u001b[0;31m# (padded area is undefined)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m     \u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_area_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pad_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m     \u001b[0;31m# And prepare iteration over all dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;31m# (zipping may be more readable than using enumerate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_pad_simple\u001b[0;34m(array, pad_width, fill_value)\u001b[0m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'F'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'C'\u001b[0m  \u001b[0;31m# Fortran and not also C-order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfill_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "for i,j in train_gen:\n",
        "    assert i[0].shape==(BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape==(BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape==    (BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "\n",
        "print ('Test Case 4 Passes!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The assert statement below took too much time while running and run time crashed so i just tested based on few items generated from the yeild keyword and they passed fine so continuing further."
      ],
      "metadata": {
        "id": "GferdcPnF0ks"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3--JT4nFMWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "train_gen = generate_batch(Xtrain, Ytrain)"
      ],
      "metadata": {
        "id": "3WIPztoNJvuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlCBCKP3Jvrf",
        "outputId": "c64c3ff9-1b69-4898-ff75-2d4ed108b8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i,j in train_gen:\n",
        "    print(\"start\")\n",
        "    assert i[0].shape==(BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape==(BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape == (BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "\n",
        "    print(i[0].shape)\n",
        "    print(i[1].shape)\n",
        "    print(j.shape)\n",
        "\n",
        "    print(\"pass\")\n",
        "    count = count + 1\n",
        "    if(count == 2):\n",
        "       break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKsoKvhUgHoj",
        "outputId": "3e8ee62f-3079-44f0-c5c7-91529cac724f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "(32, 40, 100)\n",
            "(32, 42, 100)\n",
            "(32, 42, 9742)\n",
            "pass\n",
            "start\n",
            "(32, 40, 100)\n",
            "(32, 42, 100)\n",
            "(32, 42, 9742)\n",
            "pass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52UidgSFgIvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jazC-goddcEx"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I had to upgrade Keras to new"
      ],
      "metadata": {
        "id": "xxmRLgf7GM2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png',height=400,width=400)"
      ],
      "metadata": {
        "id": "sMyLtg2jHF4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Mpb70QSgID3_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ovM77d_7HqA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKnqwC4ndcE4"
      },
      "source": [
        "# The Model architecture is explined in the diagram above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8VfVTm4dcE6"
      },
      "source": [
        "# Test-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUJbRP9SdcE8"
      },
      "source": [
        "<ol>\n",
        "<li> Step 1: Use a LSTM encoder to get input words encoded in the form of (encoder outputs, encoder hidden state, encoder context) from input words\n",
        "<li> Step 2:  Use a LSTM decoder to get target words encoded in the form of (decoder outputs, decoder hidden state, decoder context) from target words. Use encoder hidden states and encoder context (represents input memory) as initial state .\n",
        "<li> Step 3: Use a dense layer to predict the next token out of the vocabulary given decoder output generated by Step 2.\n",
        "<li> Step 4: Use loss ='categorical_crossentropy' and optimizer='rmsprop'\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "H-UkEaNzJlAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense"
      ],
      "metadata": {
        "id": "CeHDCWlZJm7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_encoder_decoder(input_vocab_size, target_vocab_size, latent_dim):\n",
        "    # Encoder\n",
        "    encoder_inputs = Input(shape=(None, input_vocab_size))\n",
        "    encoder_lstm, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_inputs)\n",
        "    encoder_states = [state_h, state_c]\n",
        "\n",
        "    # Decoder\n",
        "    decoder_inputs = Input(shape=(None, target_vocab_size))\n",
        "    decoder_lstm, _, _ = LSTM(latent_dim, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "    # Dense layer for prediction\n",
        "    dense_layer = Dense(9742, activation='softmax')\n",
        "    decoder_outputs = dense_layer(decoder_lstm)\n",
        "\n",
        "    # Model\n",
        "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "LWBn7XKPJqAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_lstm_encoder_decoder(100,100,256)"
      ],
      "metadata": {
        "id": "-aWbl-0eKpji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35d8bde-7143-4a52-e41e-032cc5630284",
        "id": "7Hw2xCQ-Kjoj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " lstm (LSTM)                 [(None, 256),                365568    ['input_1[0][0]']             \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)               [(None, None, 256),          365568    ['input_2[0][0]',             \n",
            "                              (None, 256),                           'lstm[0][1]',                \n",
            "                              (None, 256)]                           'lstm[0][2]']                \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, None, 9742)           2503694   ['lstm_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3234830 (12.34 MB)\n",
            "Trainable params: 3234830 (12.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = create_lstm_encoder_decoder(100,100,256)"
      ],
      "metadata": {
        "id": "tg0vIbEnLEJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21094533-ab06-41ff-f465-7ca15594ac1d",
        "id": "vG6a_z8SLEKI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 256),                365568    ['input_3[0][0]']             \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 256),          365568    ['input_4[0][0]',             \n",
            "                              (None, 256),                           'lstm_2[0][1]',              \n",
            "                              (None, 256)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, None, 9742)           2503694   ['lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3234830 (12.34 MB)\n",
            "Trainable params: 3234830 (12.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lksynODhLFE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNAPfQFdcFG"
      },
      "source": [
        "# Check-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecKi6g5MdcFI"
      },
      "source": [
        "Check the model summary should look like this"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21094533-ab06-41ff-f465-7ca15594ac1d",
        "id": "0jsJhX8ILtBZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " input_4 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)               [(None, 256),                365568    ['input_3[0][0]']             \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)               [(None, None, 256),          365568    ['input_4[0][0]',             \n",
            "                              (None, 256),                           'lstm_2[0][1]',              \n",
            "                              (None, 256)]                           'lstm_2[0][2]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, None, 9742)           2503694   ['lstm_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3234830 (12.34 MB)\n",
            "Trainable params: 3234830 (12.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Check as compared earlier is passed. Please note the vocabulary in the context of this notebook is 9742 so the last dense layer output is limited to 9742 enteries."
      ],
      "metadata": {
        "id": "klFUo6oBLWS9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2-ZeC66dcFJ",
        "outputId": "c2c29a26-2f9a-4d1e-96ed-a6408dbb1456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     (None, None, 100)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     (None, None, 100)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 365568      encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  365568      decoder_inputs[0][0]             \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 10002)  2570514     decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,301,650\n",
            "Trainable params: 3,301,650\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_2Z8ntzCdHSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting the model and doing some prelim predictions**"
      ],
      "metadata": {
        "id": "pd3pXblFL3tP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jLm-2zjfaA_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4D6oHYOPNvB4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initaling fitting the model with only one iteration of train data. This is just for testing."
      ],
      "metadata": {
        "id": "2zJvao20NxXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[encoder_input_data1 , decoder_input_data1], decoder_target_data1 = next(train_gen)"
      ],
      "metadata": {
        "id": "BrvcEzEMaA8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit([encoder_input_data1 , decoder_input_data1], decoder_target_data1, batch_size=32, epochs=10 )\n",
        "model1.save( 'model1.h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_TNPfzLcpDP",
        "outputId": "226763e9-73bb-4d3a-b18e-836259ce72b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 324316.1875 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 897ms/step - loss: 324304.2188 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324307.0312 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324505.5625 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324573.2500 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324699.7812 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 324808.2812 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 324887.8438 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 324950.5625 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 324990.1562 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts_word2em[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQuY-Hh3bk9T",
        "outputId": "c1f7fe98-bcaa-4f19-b3b6-234cbdd01a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.096828,  0.96216 ,  0.26631 ,  0.1745  , -0.37467 ,  0.26376 ,\n",
              "        0.49862 , -0.074503,  0.10588 ,  0.27578 , -0.10256 ,  0.16923 ,\n",
              "       -4.7434  ,  0.4171  ,  0.086999,  0.031635,  0.3348  , -0.17257 ,\n",
              "       -0.516   ,  0.01793 ,  0.24739 , -0.35023 , -0.18885 ,  0.20731 ,\n",
              "        0.075228,  0.041435,  0.27558 ,  0.1194  ,  0.2924  , -0.4688  ,\n",
              "       -0.59928 ,  0.3397  , -0.055966,  0.30236 , -0.086538,  0.82669 ,\n",
              "        0.29416 , -0.44259 ,  0.45672 ,  0.33513 , -0.40102 ,  0.14918 ,\n",
              "       -0.07679 ,  0.11941 ,  0.042608,  0.18343 ,  0.29211 , -0.9592  ,\n",
              "       -0.13515 ,  0.39735 , -0.23312 , -0.31683 ,  0.35152 , -0.45224 ,\n",
              "        0.72213 ,  0.21249 , -0.20733 ,  0.52236 ,  0.37562 , -0.38926 ,\n",
              "        0.20423 , -0.14156 , -0.092994,  0.41954 , -0.056686,  0.03899 ,\n",
              "       -0.61005 , -0.32958 , -0.50119 , -0.28287 ,  0.38674 , -0.16925 ,\n",
              "        0.71155 ,  0.37228 ,  0.51185 ,  0.2022  ,  0.5125  , -0.1919  ,\n",
              "       -0.29209 , -0.076765,  1.7907  ,  0.17052 ,  0.26721 ,  0.30087 ,\n",
              "        0.32175 ,  0.1459  ,  0.33092 ,  0.061282, -0.12012 , -0.32352 ,\n",
              "        0.25737 , -0.40787 ,  0.4293  ,  0.31119 , -0.40749 , -0.3329  ,\n",
              "        0.14969 ,  0.073275,  0.15363 , -0.44924 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts_word2em[2][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWzR5Yz6htFW",
        "outputId": "609f34cd-009c-4876-e04d-699534b7a6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.2076e-02,  9.0676e-01,  3.1419e-01,  1.4165e-01, -3.4985e-01,\n",
              "        4.5870e-01,  7.8743e-01,  7.9159e-02,  3.1101e-01,  1.1654e-01,\n",
              "       -8.4201e-02, -1.2298e-01, -4.9626e+00,  8.4222e-02, -7.1227e-01,\n",
              "       -4.1164e-01, -2.9763e-01,  2.1770e-01,  3.3573e-02, -2.2389e-01,\n",
              "       -4.1938e-02,  7.4092e-02, -1.4175e-01,  3.1477e-01,  1.8099e-01,\n",
              "       -1.7520e-01,  5.8105e-01,  3.6371e-01,  6.1984e-02, -4.8160e-01,\n",
              "       -4.0318e-01, -1.9009e-01, -3.1980e-01,  7.7435e-01,  2.4191e-01,\n",
              "        5.2341e-01, -1.3669e-01, -2.2893e-01,  9.5895e-02,  2.9128e-04,\n",
              "       -6.6452e-01,  8.2740e-02,  1.7683e-01, -5.5643e-02,  4.1171e-01,\n",
              "        4.0244e-02,  3.0529e-01, -2.7427e-01, -3.0539e-02,  4.4709e-01,\n",
              "        2.0210e-02, -2.8307e-01,  9.0796e-01,  4.2457e-02,  1.4095e-01,\n",
              "       -6.0346e-01, -4.9815e-01,  6.4657e-01, -1.7250e-01,  4.2005e-01,\n",
              "        3.1790e-01, -3.4210e-02, -3.0226e-01,  2.4460e-01, -8.3227e-02,\n",
              "       -3.9928e-01, -6.9852e-02, -5.8187e-02, -7.0117e-01,  2.5653e-01,\n",
              "        1.2569e-01,  1.9799e-01, -2.1939e-01,  5.6393e-02, -3.4210e-01,\n",
              "       -2.5463e-01,  4.3919e-01, -9.7505e-02, -1.1473e-01,  1.5477e-01,\n",
              "        1.4656e+00,  2.5907e-01, -1.5941e-01, -4.3826e-01,  5.6633e-01,\n",
              "        2.7206e-02, -1.1308e-01,  1.2632e-01, -4.7401e-01,  1.4754e-01,\n",
              "       -4.8879e-01, -1.3351e-01, -2.8056e-01, -3.0709e-01, -2.0114e-01,\n",
              "        1.9387e-01, -3.9040e-02,  4.5799e-01,  4.0672e-01,  4.6363e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = \"good\""
      ],
      "metadata": {
        "id": "FEF1Ab2nrkn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = word2embedding[p1]"
      ],
      "metadata": {
        "id": "mJlDGNRUvHJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2embedding['do']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC0M935QvO0C",
        "outputId": "fb35d552-f6d0-4fe6-d6c1-b5d3dc70d3a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.3741e-01, -2.2434e-01,  9.1622e-01, -5.8550e-02, -1.6511e-01,\n",
              "        2.5111e-01,  6.0232e-01, -5.0023e-01,  5.4699e-01,  6.9742e-01,\n",
              "       -2.0822e-01, -1.1138e+00, -5.3540e+00,  4.4314e-01, -5.4168e-01,\n",
              "       -1.7297e-01, -8.2312e-01, -2.0724e-01,  5.2782e-01, -2.1240e-01,\n",
              "        2.9266e-02, -7.1848e-02, -1.3079e-01, -7.4409e-02,  3.6398e-01,\n",
              "       -1.7687e+00,  5.0954e-01,  7.1843e-01,  1.6063e-01, -1.3972e-01,\n",
              "        9.4257e-01, -4.2210e-01,  4.7313e-02, -4.6057e-01, -1.0714e+00,\n",
              "       -2.8972e-03,  1.9650e-01, -5.9106e-01, -1.1389e+00,  1.5337e-01,\n",
              "       -2.1414e+00,  7.8533e-01,  1.0681e-01, -1.0814e-01, -6.3045e-01,\n",
              "        2.1288e-01, -9.9607e-02, -4.1917e-01, -5.7476e-01, -1.1047e+00,\n",
              "        5.3964e-01,  4.9028e-01,  2.6830e-01,  2.7167e-01,  1.6113e-01,\n",
              "        4.2814e-01, -9.7108e-01,  7.5670e-01, -2.8024e-02,  5.9043e-01,\n",
              "       -2.5249e-01, -1.4199e-01,  3.4776e-01,  8.7260e-02,  1.6208e-01,\n",
              "       -1.3040e-01,  2.7808e-02, -2.5873e-01, -1.1011e-02,  1.3697e-01,\n",
              "        2.6576e-01, -7.3448e-01, -1.3408e-01, -1.7406e-01, -6.3658e-02,\n",
              "       -5.4090e-01,  3.1872e-01, -3.6860e-01,  4.6780e-03,  4.5205e-01,\n",
              "        4.4172e-01,  3.5350e-01, -8.2819e-01,  3.2221e-01,  7.2283e-01,\n",
              "        7.4891e-01,  3.5870e-01, -2.9725e-01,  3.9902e-02, -1.4895e-01,\n",
              "       -1.0915e+00,  5.3089e-01,  3.6266e-02, -7.1258e-01, -5.5899e-01,\n",
              "        1.0474e-01,  1.8477e-01,  4.7999e-01,  2.7531e-01,  5.0398e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(p1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuuki5Z0vZo-",
        "outputId": "99c8f088-3a7c-46df-9f61-afcfb45cec5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngfLgubsvvph",
        "outputId": "a4990a4c-73f1-4891-d47b-76f888333887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p2 = np.pad(p1, (127900, 0), 'constant', constant_values=(0, 0))\n",
        "p2 = p2.reshape(32,encoder_max_seq_length,GLOVE_EMBEDDING_SIZE)"
      ],
      "metadata": {
        "id": "vgrKJ-94vvmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k-jfUCEvvjx",
        "outputId": "d79de54c-2f16-4035-ef00-00318be04021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 40, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p3 = np.pad(p1, (134300, 0), 'constant', constant_values=(0, 0))\n",
        "p3 = p3.reshape(32,decoder_max_seq_length,GLOVE_EMBEDDING_SIZE)"
      ],
      "metadata": {
        "id": "NblKacKsxcod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p4 = np.pad(p1, (127900, 0), 'constant', constant_values=(0, 0))\n",
        "p4 = p4.reshape(32,encoder_max_seq_length,GLOVE_EMBEDDING_SIZE)"
      ],
      "metadata": {
        "id": "OmEDqkEq1AYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = model1.predict([p2,p4],9702)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCLgjjYn1g4Z",
        "outputId": "673bc00d-01fd-437c-cd0b-b8b2e3a159c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp9k3TYe1P9f",
        "outputId": "2d01b8bc-f90a-4b83-9e07-c0b19edc5fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 40, 9742)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0][0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfkzxnWk4pu2",
        "outputId": "21ce4bd9-ba7f-480e-d9e2-205dfde6e3a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.3096258e-04, 1.1071931e-04, 5.0569699e-05, ..., 8.6397646e-05,\n",
              "       1.0339828e-04, 8.7820627e-05], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the predicted result find the first word of the response. The output of the model is of shape (32,40,9742 ). Since this is sequnce to sequence problem so we are ideally interested in max probability word  in the 40 sequences generated in first batch.\n",
        "\n",
        "predicted_array[0][0][value with highest probability]"
      ],
      "metadata": {
        "id": "ZuiVXeZ_OHrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sum = 0\n",
        "\n",
        "for i in range(0,9742):\n",
        "  sum = sum + y[0][0][i]\n"
      ],
      "metadata": {
        "id": "7snLtcRh5hf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpDBTFI35yla",
        "outputId": "3651be93-1883-4ff6-9d80-ccf4d7511731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999850010681"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max1 = 0\n",
        "max_index1 = 0\n",
        "\n",
        "for i in range(0,9742):\n",
        "  if (max1 < y[0][3][i]):\n",
        "      max1 = y[0][0][i]\n",
        "      max_index1 = i\n",
        "\n"
      ],
      "metadata": {
        "id": "VPlF1eQV51S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUgB3SiS8uWY",
        "outputId": "a6ce6d7c-5fe8-439d-f3f6-b730fb6f064e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0002050376"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_index1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg-14jaK8wqj",
        "outputId": "44c90f4e-fb41-42c5-f391-3ff54fafbeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6439"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_idx2word_new1[6439]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gGgBgu4d8zFV",
        "outputId": "392b22b7-376e-44ae-dd98-8a652301b10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gaston'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yIl6EHsY98kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating one more model this one would be trained for 30 batches ( due to resource  restrictions ) and analying the results."
      ],
      "metadata": {
        "id": "y4o3wxq8PWBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = create_lstm_encoder_decoder(100,100,256)"
      ],
      "metadata": {
        "id": "xPajYX8998hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu0d8Xp798e6",
        "outputId": "b9f28f57-2551-4294-de13-8efaf664bdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)        [(None, None, 100)]          0         []                            \n",
            "                                                                                                  \n",
            " lstm_4 (LSTM)               [(None, 256),                365568    ['input_5[0][0]']             \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_5 (LSTM)               [(None, None, 256),          365568    ['input_6[0][0]',             \n",
            "                              (None, 256),                           'lstm_4[0][1]',              \n",
            "                              (None, 256)]                           'lstm_4[0][2]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, None, 9742)           2503694   ['lstm_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3234830 (12.34 MB)\n",
            "Trainable params: 3234830 (12.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,30):\n",
        "\n",
        "  [encoder_input_data1 , decoder_input_data1], decoder_target_data1 = next(train_gen)\n",
        "  model2.fit([encoder_input_data1 , decoder_input_data1], decoder_target_data1, batch_size=32, epochs=10 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KVHpTxuBcbb",
        "outputId": "2569902e-d24e-4f8b-f8e5-c95b569535c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 5s 5s/step - loss: 324311.5625 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 839ms/step - loss: 324301.5312 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 799ms/step - loss: 324294.9062 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 805ms/step - loss: 324327.0625 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 324406.4375 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 324548.4375 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 324675.2188 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 324774.0625 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 324839.1875 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 324881.5312 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324909.7188 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 812ms/step - loss: 324928.1562 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 324939.9062 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 324948.8750 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 324955.2812 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1000ms/step - loss: 324959.0000 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324962.1875 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324965.2500 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324966.9375 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 324968.3750 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 324970.2188 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324971.1562 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324971.8438 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 324972.4062 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 324972.9375 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 804ms/step - loss: 324973.3438 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 324973.7500 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 324974.0625 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 324974.3438 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 324974.5938 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324974.8438 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 324975.0625 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 784ms/step - loss: 324975.2812 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 324975.4688 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 324975.6562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 324976.0312 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324976.3438 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 324976.5938 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 769ms/step - loss: 324976.8438 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 888ms/step - loss: 324977.0625 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 932ms/step - loss: 324977.3438 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 324977.5625 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 324977.7500 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 324977.9062 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324978.1250 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324978.2500 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324978.3750 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324978.5625 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 814ms/step - loss: 324978.6562 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 324978.7500 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 324978.9062 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324979.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 954ms/step - loss: 324979.0625 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 811ms/step - loss: 324979.1562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 324979.2500 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 324979.3125 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 324979.3750 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 324979.4375 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 324979.4688 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 324979.5625 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 905ms/step - loss: 324979.5625 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 324979.6250 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 324979.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 324979.7188 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 324979.7500 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324979.8125 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 324979.8125 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 770ms/step - loss: 324979.8750 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 752ms/step - loss: 324979.8438 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 956ms/step - loss: 324979.9062 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 324979.9375 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 324979.9375 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 324979.9688 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 324980.0000 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 879ms/step - loss: 324980.0000 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.0625 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.0625 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.0625 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 937ms/step - loss: 324980.1250 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 324980.0938 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 324980.0938 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.1250 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.1250 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 871ms/step - loss: 324980.1562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 324980.1562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 324980.1562 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 802ms/step - loss: 324980.1562 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 324980.1875 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 324980.2188 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 324980.2188 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 910ms/step - loss: 324980.2500 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 324980.2188 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 324980.2500 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 324980.2500 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 324980.2812 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 324980.3125 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 324980.3438 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 324980.3438 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 324980.3438 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 737ms/step - loss: 324980.3750 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 919ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 797ms/step - loss: 324980.4688 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 324980.5312 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5000 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5312 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5312 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 865ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 796ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 755ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 922ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324980.6875 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 324980.7188 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324980.6875 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 324980.7188 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 324980.7188 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 324980.7188 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 324980.6875 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 324980.7188 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 790ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 786ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 761ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 894ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 777ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 801ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 738ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 800ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 813ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 834ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 836ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 763ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 747ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 762ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 912ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 781ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 760ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 324980.6562 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 324980.5938 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 798ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 795ms/step - loss: 324980.6250 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 809ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 750ms/step - loss: 324980.5312 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.5625 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.4688 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 324980.5000 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 324980.4688 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 324980.5000 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 768ms/step - loss: 324980.5000 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 324980.5000 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 743ms/step - loss: 324980.4688 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 736ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 903ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 324980.4062 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 791ms/step - loss: 324980.3750 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 783ms/step - loss: 324980.4062 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 753ms/step - loss: 324980.4375 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 746ms/step - loss: 324980.3750 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 749ms/step - loss: 324980.4062 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 324980.3750 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 895ms/step - loss: 324980.3750 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 765ms/step - loss: 324980.4062 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324980.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324968.6250 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324967.9375 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324966.8438 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 885ms/step - loss: 324973.7500 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 324973.2500 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 723ms/step - loss: 324981.3125 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 733ms/step - loss: 324981.9062 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324982.0938 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324982.1562 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 324982.1562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 782ms/step - loss: 324982.1562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 324982.1562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 764ms/step - loss: 324982.1250 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 324982.1250 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 324982.0938 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 324982.1250 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 324982.1250 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 324982.0938 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 780ms/step - loss: 324982.0938 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 775ms/step - loss: 324982.0938 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 789ms/step - loss: 324982.1562 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 772ms/step - loss: 324982.1562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 324982.1875 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 324982.2812 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 745ms/step - loss: 324982.5625 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 324983.1562 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 740ms/step - loss: 324983.7812 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 924ms/step - loss: 324983.9375 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 788ms/step - loss: 324984.0000 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 822ms/step - loss: 324984.0938 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 774ms/step - loss: 324984.0938 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 324984.1562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 785ms/step - loss: 324984.2188 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 816ms/step - loss: 324984.2812 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 324984.3438 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 827ms/step - loss: 324984.3750 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324984.3750 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 962ms/step - loss: 324984.4375 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 324984.5312 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 324984.5625 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324984.5625 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324984.6562 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324984.7188 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324984.8750 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 739ms/step - loss: 324985.1875 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 754ms/step - loss: 324985.8438 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 756ms/step - loss: 324986.6562 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324986.8750 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324986.9375 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324987.0000 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324987.0938 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 324987.3125 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 773ms/step - loss: 324987.8125 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 767ms/step - loss: 324988.3438 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 748ms/step - loss: 324988.5312 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 732ms/step - loss: 324988.5625 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 731ms/step - loss: 324988.6250 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324988.6250 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 793ms/step - loss: 324988.6562 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 787ms/step - loss: 324988.6562 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324988.7188 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 324988.7500 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 779ms/step - loss: 324988.7500 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 758ms/step - loss: 324988.8125 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 742ms/step - loss: 324988.8438 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 759ms/step - loss: 324988.9062 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 735ms/step - loss: 324988.9375 - accuracy: 0.0000e+00\n",
            "Epoch 1/10\n",
            "1/1 [==============================] - 1s 898ms/step - loss: 324989.0000 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 324989.0312 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 324989.0312 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 1s 771ms/step - loss: 324989.0938 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 1s 778ms/step - loss: 324989.0938 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 1s 776ms/step - loss: 324989.1562 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 1s 757ms/step - loss: 324989.1875 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 1s 741ms/step - loss: 324989.2500 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324989.3438 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 1s 1s/step - loss: 324989.3438 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model for later use"
      ],
      "metadata": {
        "id": "eEnn3gR6Py53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2.save( 'model2.h5' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeLQ8vEGH11u",
        "outputId": "6b64007b-a739-431b-f50b-1b72dfd6f63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_seq = \"how are you\""
      ],
      "metadata": {
        "id": "YBLfpeEcH7j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "y9g0VbV7wd7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2=load_model('model2.h5')"
      ],
      "metadata": {
        "id": "nKsiHqJNvYVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to encode a sequence which is used as test to see the results from the model"
      ],
      "metadata": {
        "id": "xRcw7VSvQCYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def encode_1(s):\n",
        "  j=0\n",
        "  splitStr = s.split(\" \");\n",
        "  #print(splitStr)\n",
        "  for i in range(0,len(splitStr)):\n",
        "    if(i == 0):\n",
        "      in_arr = word2embedding[s[i]]\n",
        "      #print(in_arr.shape)\n",
        "\n",
        "    else:\n",
        "      #print(word2embedding[s[i]].shape)\n",
        "      in_arr = np.append(in_arr, word2embedding[s[i]])\n",
        "\n",
        "  pad_factor1 = 32*40*100 - len(splitStr)*100\n",
        "  pad_in_arr = np.pad(in_arr, (0, pad_factor1), 'constant', constant_values=(0, 0))\n",
        "  pad_in_arr1 = pad_in_arr.reshape(32,40,100)\n",
        "  #print(pad_in_arr1.shape)\n",
        "\n",
        "  '''\n",
        "  pad_in_arr1 = np.pad(pad_in_arr1, (124000, 0), 'constant', constant_values=(0, 0),axis=0)\n",
        "  print(pad_in_arr.shape)\n",
        "  pad_in_arr1 = pad_in_arr1.reshape(32,40,100)\n",
        "  '''\n",
        "\n",
        "  return pad_in_arr1\n"
      ],
      "metadata": {
        "id": "7FPlOkdwIgxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dGLT6-WFnRsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_seq = \"how are you\""
      ],
      "metadata": {
        "id": "fK3MZ-IFQVGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_array = encode_1(input_test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuiNYvGFMsa-",
        "outputId": "cc2e5620-9335-42e4-bb62-677a5122e610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['how', 'are', 'you']\n",
            "(100,)\n",
            "(100,)\n",
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPGA6uVtR9S-",
        "outputId": "63e597d5-92d4-4d01-b852-554ae6e5529b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 40, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = model2.predict([input_test_array,input_test_array])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytBeKkGbrmF-",
        "outputId": "0d7f5f21-b2f7-4fee-e2c2-6e84c3890bff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max1 = 0\n",
        "max_index1 = 0\n",
        "\n",
        "\n",
        "for i in range(0,9742):\n",
        "  if (max1 < x[0][0][i]):\n",
        "      max1 = x[0][0][i]\n",
        "      max_index1 = i"
      ],
      "metadata": {
        "id": "aq3eDVuFsnEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rse7vMo7snBj",
        "outputId": "867fbd04-47b5-4da2-f38c-f121dab69fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00022670299"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_index1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOG_NP6QrmC3",
        "outputId": "b4d1fe68-6135-4c3f-d729-0412e1ca996b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6674"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_idx2word_new1[6674]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mN9meV0Vv1K3",
        "outputId": "6109c9a6-3355-43b6-8acc-6fd8378eb213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tourist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5qRPVFQQ3YI"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_nsfM8eQ3YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction1(pred):\n",
        "  print(\"##############.  Printing the prediction from four sequences of the predicted Array.  #################\")\n",
        "  print(\"  \")\n",
        "  max_index1 = []\n",
        "  for i in range(0,4):\n",
        "    max1 = 0\n",
        "\n",
        "\n",
        "    for j in range(0,9742):\n",
        "      if (max1 < pred[0][i][j]):\n",
        "            max1 = pred[0][i][j]\n",
        "            index = j\n",
        "    max_index1.append(index)\n",
        "    #print(max_index1)\n",
        "\n",
        "  for item in max_index1:\n",
        "    print(target_idx2word_new1[item],end =\" \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ji1TKdd6Q3YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_seq1 = \"can i speak\""
      ],
      "metadata": {
        "id": "-e4UfsP7Q5Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_test_seq2 = \"speak i can\""
      ],
      "metadata": {
        "id": "-_0nz9MUQ5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_array1 = encode_1(input_test_seq1)\n",
        "input_test_array2 = encode_1(decode_test_seq2)"
      ],
      "metadata": {
        "id": "UsVO9udXQ5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_array1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd01adb8-c7ed-420a-8fa5-3fc8e4cc6bed",
        "id": "e8k2hT9EQ5Nw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 40, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_test_array2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce79318-e1ff-434d-d593-86228c0142b4",
        "id": "BxiwwPhOQ5Nw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 40, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model2.predict([input_test_array1,input_test_array2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d68ad446-0313-4083-e61f-11c699964484",
        "id": "_83Ia3UjQ5Nw"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 304ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction1(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff51d1f-fa44-4dbe-8ec7-61dc64f963b8",
        "id": "wpbRk0zTQ5Nx"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##############.  Printing the prediction from four sequences of the predicted Array.  #################\n",
            "  \n",
            "tourist crunch brain well "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-oyUT3Z6Q5Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "********************************************************.  END **********************************************************"
      ],
      "metadata": {
        "id": "dQ0iAARmQ5Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qBNvhtyQ5Nx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6PzuUg4zdcER"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}